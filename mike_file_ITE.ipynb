{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c846bad5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3170729",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# ITE in a simple RCT\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "\n",
    "##### DGP ########\n",
    "dgp <- function(n_obs=20000, doX=c(NA, NA, NA, NA), SEED=123, \n",
    "                p=2, p0=0, confounder=FALSE, main_effect = -0.85,\n",
    "                interaction_effect = 0.7) {\n",
    "  #n_obs = 1e5 n_obs = 10\n",
    "  set.seed(SEED)\n",
    "  \n",
    "  # Data simulation\n",
    "  \n",
    "  ## Case 1: continuous random variables\n",
    "  \n",
    "  # Define sample size\n",
    "  n <- n_obs\n",
    "  \n",
    "  # Generate random binary treatment T\n",
    "  Tr <- rbinom(n, size = 1, prob = 0.5)\n",
    "  \n",
    "  # p <- 2  # number of variables \n",
    "  \n",
    "  # Define the mean vector (all zeros for simplicity)\n",
    "  mu <- rep(0, p+p0)  # Mean vector of length p\n",
    "  \n",
    "  # Define the covariance matrix (compound symmetric for simplicity)\n",
    "  rho <- 0.1  # Correlation coefficient\n",
    "  Sigma <- matrix(rho, nrow = (p+p0), ncol = (p+p0))  # Start with all elements as rho\n",
    "  diag(Sigma) <- 1  # Set diagonal elements to 1 (variances)\n",
    "  \n",
    "  # Generate n samples from the multivariate normal distribution\n",
    "  data <- MASS::mvrnorm(n, mu = mu, Sigma = Sigma)\n",
    "  colnames(data) <- paste0(\"X\", 1:(p+p0))\n",
    "  \n",
    "  beta_0 <- 0.45\n",
    "  beta_t <- main_effect # -0.85 default\n",
    "  beta_X <- c(-0.5, 0.1, rep(0, p0))  # p0 variables with no effect on outcome\n",
    "  beta_TX <- interaction_effect # 0.7 default\n",
    "  \n",
    "  if(confounder) {\n",
    "    # Add use the first variable X1 as confounder to affect Tr\n",
    "    Tr <- rbinom(n, size = 1, prob = plogis(0.5 * data[,1]))\n",
    "  }\n",
    "  \n",
    "  # Calculate the linear predictor (logit)\n",
    "  logit_Y <- beta_0 + beta_t * Tr + data %*% beta_X + (data[,1] * beta_TX) * Tr\n",
    "  \n",
    "  \n",
    "  # Convert logit to probability of outcome\n",
    "  Y_prob <- plogis(logit_Y)\n",
    "  \n",
    "  # Generate binary outcome Y based on the probability\n",
    "  Y <- rbinom(n, size = 1, prob = Y_prob)\n",
    "  \n",
    "  # Potential outcome for treated and untreated\n",
    "  Y1 <- plogis(beta_0 + beta_t + data %*% beta_X + data[,1] * beta_TX)\n",
    "  # Y1 <- plogis(beta_0 + beta_t + data %*% beta_X + data %*% beta_TX)\n",
    "  Y0 <- plogis(beta_0 + data %*% beta_X)\n",
    "  \n",
    "  # Calculate the individual treatment effect\n",
    "  ITE_true <- Y1 - Y0\n",
    "  # summary(data)\n",
    "  # sd(data[,1])\n",
    "  # mean(data[,1])\n",
    "  # \n",
    "  # data[,1] <- scale(data[,1])\n",
    "  # data[,2] <- (data[,2]-mean(data[,2]))/sd(data[,2])\n",
    "  \n",
    "  # Combine all variables into a single data frame\n",
    "  simulated_full_data <- data.frame(ID = 1:n, Y=Y, Treatment=Tr, data, Y1, Y0, ITE_true, Y_prob)\n",
    "  \n",
    "  # Data for testing ITE models\n",
    "  simulated_data <- data.frame(ID =1:n, Y=Y, Treatment=Tr, Tr=Tr, data, ITE_true = ITE_true, Y_prob=Y_prob) %>% \n",
    "    # add Treatment variable Tr=Treatment\n",
    "    mutate(Treatment = ifelse(Treatment==1,\"Y\", \"N\")) %>% \n",
    "    mutate(Treatment = factor(Treatment, levels = c(\"N\", \"Y\")))\n",
    "  \n",
    "  \n",
    "  set.seed(12345)\n",
    "  test.data <- split_data(simulated_data, 1/2)\n",
    "  test.compl.data <- remove_NA_data(test.data)\n",
    "  \n",
    "  \n",
    "  # for two-model structure we only need the 2 patient specific variables (no Tr)\n",
    "  A <- matrix(c(0, 0, 0, 1, \n",
    "                0, 0, 0, 1,\n",
    "                0, 0, 0, 1,\n",
    "                0, 0, 0, 0), nrow = 4, ncol = 4, byrow = TRUE)\n",
    "  \n",
    "  # Full dataset\n",
    "  dat.orig =  data.frame(x1 = simulated_full_data$Treatment, \n",
    "                         x2 = simulated_full_data$X1, \n",
    "                         x3 = simulated_full_data$X2, \n",
    "                         x4 = simulated_full_data$Y)\n",
    "  dat_temp <- as.matrix(dat.orig)\n",
    "  # dat_temp[,4] <- dat_temp[,4] + 1\n",
    "  dat_temp[,c(1,4)] <- dat_temp[,c(1,4)] + 1\n",
    "  dat.tf = tf$constant(as.matrix(dat_temp), dtype = 'float32')\n",
    "  \n",
    "  # train dataset\n",
    "  dat.train <- data.frame(x1 = test.compl.data$data.dev$Tr, \n",
    "                          x2 = test.compl.data$data.dev$X1, \n",
    "                          x3 = test.compl.data$data.dev$X2, \n",
    "                          x4 = test.compl.data$data.dev$Y)\n",
    "  dat_temp <- as.matrix(dat.train)\n",
    "  # dat_temp[,4] <- dat_temp[,4] + 1\n",
    "  dat_temp[,c(1,4)] <- dat_temp[,c(1,4)] + 1\n",
    "  dat.train.tf = tf$constant(as.matrix(dat_temp), dtype = 'float32')\n",
    "  \n",
    "  dat.test <- data.frame(x1 = test.compl.data$data.val$Tr, \n",
    "                         x2 = test.compl.data$data.val$X1, \n",
    "                         x3 = test.compl.data$data.val$X2, \n",
    "                         x4 = test.compl.data$data.val$Y)\n",
    "  dat_temp <- as.matrix(dat.test)\n",
    "  # dat_temp[,4] <- dat_temp[,4] + 1\n",
    "  dat_temp[,c(1,4)] <- dat_temp[,c(1,4)] + 1\n",
    "  dat.test.tf = tf$constant(as.matrix(dat_temp), dtype = 'float32')\n",
    "  \n",
    "  \n",
    "  q1 = c(1, 2)\n",
    "  q2 = quantile(dat.orig[,2], probs = c(0.05, 0.95))\n",
    "  q3 = quantile(dat.orig[,3], probs = c(0.05, 0.95))\n",
    "  q4 = c(1, 2) #No Quantiles for ordinal data\n",
    "  # q1 = quantile(dat.orig[,2], probs = c(0.05, 0.95)) \n",
    "  # q2 = quantile(dat.orig[,3], probs = c(0.05, 0.95))\n",
    "  # q3 = c(0, 1) #No Quantiles for ordinal data\n",
    "  \n",
    "  \n",
    "  return(list(\n",
    "    df_orig=dat.tf, \n",
    "    df_R = dat.orig,\n",
    "    min =  tf$reduce_min(dat.tf, axis=0L),\n",
    "    max =  tf$reduce_max(dat.tf, axis=0L),\n",
    "    min = tf$constant(c(q1[1], q2[1], q3[1], q4[1]), dtype = 'float32'),\n",
    "    max = tf$constant(c(q1[2], q2[2], q3[2], q4[2]), dtype = 'float32'),\n",
    "    \n",
    "    # min = tf$constant(c(q1[1], q2[1], q3[1]), dtype = 'float32'),\n",
    "    # max = tf$constant(c(q1[2], q2[2], q3[2]), dtype = 'float32'),\n",
    "    type = c('o', 'c', 'c', 'o'),\n",
    "    A=A,\n",
    "    \n",
    "    #train\n",
    "    df_R_train = dat.train,\n",
    "    df_orig_train = dat.train.tf,\n",
    "    \n",
    "    \n",
    "    # df_orig_train_ct = dat.train.ct.tf,\n",
    "    # df_R_train_ct = dat.train.ct,\n",
    "    # \n",
    "    # df_orig_train_tx = dat.train.tx.tf,\n",
    "    # df_R_train_tx = dat.train.tx,\n",
    "    \n",
    "    #test\n",
    "    df_R_test = dat.test,\n",
    "    df_orig_test = dat.test.tf,\n",
    "    \n",
    "    # df_orig_test_ct = dat.test.ct.tf,\n",
    "    # df_R_test_ct = dat.test.ct,\n",
    "    # \n",
    "    # df_orig_test_tx = dat.test.tx.tf,\n",
    "    # df_R_test_tx = dat.test.tx,\n",
    "    # \n",
    "    #full\n",
    "    simulated_full_data = simulated_full_data,\n",
    "    simulated_data = simulated_data,\n",
    "    test.compl.data = test.compl.data,\n",
    "    dgp_params = list(\n",
    "      beta_0 = beta_0,\n",
    "      beta_t = beta_t,\n",
    "      beta_X = beta_X,\n",
    "      beta_TX = beta_TX\n",
    "    )\n",
    "  ))\n",
    "} \n",
    "\n",
    "\n",
    "n_obs <- 20000\n",
    "\n",
    "# specify number of predictor variables\n",
    "p <- 2\n",
    "\n",
    "# specify number of variables without effect\n",
    "p0 <- 0\n",
    "\n",
    "dgp_data = dgp(n_obs, p=p, p0=p0, SEED=123, confounder=FALSE)\n",
    "\n",
    "# percentage of patients with Y=1\n",
    "mean(dgp_data$simulated_full_data$Y)\n",
    "\n",
    "# percentage of patients with Y=1 in Control (train)\n",
    "mean(dgp_data$test.compl.data$data.dev.ct$Y)\n",
    "\n",
    "# percentage of patients with Y=1 in Treatment (train)\n",
    "mean(dgp_data$test.compl.data$data.dev.tx$Y)\n",
    "\n",
    "dgp_data$df_orig_test\n",
    "\n",
    "dgp_data$simulated_full_data\n",
    "\n",
    "boxplot(Y_prob ~ Y, data = dgp_data$simulated_full_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### new dgp for simulation (for choosing kriteria)\n",
    "\n",
    "\n",
    "##### DGP ########\n",
    "dgp_simulation <- function(n_obs=20000, doX=c(NA, NA, NA, NA), SEED=123,\n",
    "                beta_0 = 0.45,\n",
    "                beta_t = -0.85,\n",
    "                beta_X = c(-0.5, 0.1),\n",
    "                beta_TX = c(0.7),\n",
    "                p0 = 0, \n",
    "                confounder=FALSE,\n",
    "                drop=FALSE) {\n",
    "  #n_obs = 1e5 n_obs = 10\n",
    "  set.seed(SEED)\n",
    "  \n",
    "  # Data simulation\n",
    "  \n",
    "  # Define sample size\n",
    "  n <- n_obs\n",
    "  \n",
    "  p <- length(beta_X) # number of variables with effect\n",
    "  \n",
    "  # Define the mean vector (all zeros for simplicity)\n",
    "  mu <- rep(0, p+p0)  # Mean vector of length p\n",
    "  \n",
    "  # Define the covariance matrix (compound symmetric for simplicity)\n",
    "  rho <- 0.1  # Correlation coefficient\n",
    "  Sigma <- matrix(rho, nrow = (p+p0), ncol = (p+p0))  # Start with all elements as rho\n",
    "  diag(Sigma) <- 1  # Set diagonal elements to 1 (variances)\n",
    "  \n",
    "  # Generate n samples from the multivariate normal distribution\n",
    "  data <- MASS::mvrnorm(n, mu = mu, Sigma = Sigma)\n",
    "  colnames(data) <- paste0(\"X\", 1:(p+p0))\n",
    "  \n",
    "  beta_0 <- beta_0\n",
    "  beta_t <- beta_t # -0.85 default\n",
    "  beta_X <- c(beta_X, rep(0, p0))  # p0 variables with no effect on outcome\n",
    "  beta_TX <- beta_TX # 0.7 default\n",
    "  \n",
    "  if(confounder != FALSE) {\n",
    "    # Add use the first variable X1 as confounder to affect Tr\n",
    "    Tr <- rbinom(n, size = 1, prob = plogis(0.5 * data[,confounder]))\n",
    "  } else {\n",
    "    # Generate random binary treatment T\n",
    "    Tr <- rbinom(n, size = 1, prob = 0.5)\n",
    "  }\n",
    "  \n",
    "  # Calculate the linear predictor (logit)\n",
    "  logit_Y <- beta_0 + beta_t * Tr + data %*% beta_X + (as.matrix(data[,c(1:length(beta_TX))]) %*% beta_TX) * Tr\n",
    "  \n",
    "  \n",
    "  # Convert logit to probability of outcome\n",
    "  Y_prob <- plogis(logit_Y)\n",
    "  \n",
    "  # Generate binary outcome Y based on the probability\n",
    "  Y <- rbinom(n, size = 1, prob = Y_prob)\n",
    "  \n",
    "  # Potential outcome for treated and untreated\n",
    "  Y1 <- plogis(beta_0 + beta_t + data %*% beta_X + data[,1] * beta_TX)\n",
    "  # Y1 <- plogis(beta_0 + beta_t + data %*% beta_X + data %*% beta_TX)\n",
    "  Y0 <- plogis(beta_0 + data %*% beta_X)\n",
    "  \n",
    "  # Calculate the individual treatment effect\n",
    "  ITE_true <- Y1 - Y0\n",
    "  # summary(data)\n",
    "  # sd(data[,1])\n",
    "  # mean(data[,1])\n",
    "  # \n",
    "  # data[,1] <- scale(data[,1])\n",
    "  # data[,2] <- (data[,2]-mean(data[,2]))/sd(data[,2])\n",
    "  \n",
    "  # Combine all variables into a single data frame\n",
    "  simulated_full_data <- data.frame(ID = 1:n, Y=Y, Treatment=Tr, data, Y1, Y0, ITE_true, Y_prob)\n",
    "  \n",
    "  # Data for testing ITE models\n",
    "  simulated_data <- data.frame(ID =1:n, Y=Y, Treatment=Tr, Tr=Tr, data, ITE_true = ITE_true, Y_prob=Y_prob) %>% \n",
    "    # add Treatment variable Tr=Treatment\n",
    "    mutate(Treatment = ifelse(Treatment==1,\"Y\", \"N\")) %>% \n",
    "    mutate(Treatment = factor(Treatment, levels = c(\"N\", \"Y\")))\n",
    "  \n",
    "  \n",
    "  set.seed(12345)\n",
    "  test.data <- split_data(simulated_data, 1/2)\n",
    "  test.compl.data <- remove_NA_data(test.data)\n",
    "  \n",
    "  \n",
    "  # for two-model structure we only need the 2 patient specific variables (no Tr)\n",
    "  A <- matrix(c(0, 0, 0, 1, \n",
    "                0, 0, 0, 1,\n",
    "                0, 0, 0, 1,\n",
    "                0, 0, 0, 0), nrow = 4, ncol = 4, byrow = TRUE)\n",
    "  \n",
    "  # Full dataset\n",
    "  dat.orig =  data.frame(x1 = simulated_full_data$Treatment, \n",
    "                         x2 = simulated_full_data$X1, \n",
    "                         x3 = simulated_full_data$X2, \n",
    "                         x4 = simulated_full_data$Y)\n",
    "  dat_temp <- as.matrix(dat.orig)\n",
    "  # dat_temp[,4] <- dat_temp[,4] + 1\n",
    "  dat_temp[,c(1,4)] <- dat_temp[,c(1,4)] + 1\n",
    "  dat.tf = tf$constant(as.matrix(dat_temp), dtype = 'float32')\n",
    "  \n",
    "  # train dataset\n",
    "  dat.train <- data.frame(x1 = test.compl.data$data.dev$Tr, \n",
    "                          x2 = test.compl.data$data.dev$X1, \n",
    "                          x3 = test.compl.data$data.dev$X2, \n",
    "                          x4 = test.compl.data$data.dev$Y)\n",
    "  dat_temp <- as.matrix(dat.train)\n",
    "  # dat_temp[,4] <- dat_temp[,4] + 1\n",
    "  dat_temp[,c(1,4)] <- dat_temp[,c(1,4)] + 1\n",
    "  dat.train.tf = tf$constant(as.matrix(dat_temp), dtype = 'float32')\n",
    "  \n",
    "  dat.test <- data.frame(x1 = test.compl.data$data.val$Tr, \n",
    "                         x2 = test.compl.data$data.val$X1, \n",
    "                         x3 = test.compl.data$data.val$X2, \n",
    "                         x4 = test.compl.data$data.val$Y)\n",
    "  dat_temp <- as.matrix(dat.test)\n",
    "  # dat_temp[,4] <- dat_temp[,4] + 1\n",
    "  dat_temp[,c(1,4)] <- dat_temp[,c(1,4)] + 1\n",
    "  dat.test.tf = tf$constant(as.matrix(dat_temp), dtype = 'float32')\n",
    "  \n",
    "  \n",
    "  q1 = c(1, 2)\n",
    "  q2 = quantile(dat.orig[,2], probs = c(0.05, 0.95))\n",
    "  q3 = quantile(dat.orig[,3], probs = c(0.05, 0.95))\n",
    "  q4 = c(1, 2) #No Quantiles for ordinal data\n",
    "  # q1 = quantile(dat.orig[,2], probs = c(0.05, 0.95)) \n",
    "  # q2 = quantile(dat.orig[,3], probs = c(0.05, 0.95))\n",
    "  # q3 = c(0, 1) #No Quantiles for ordinal data\n",
    "  \n",
    "  \n",
    "  return(list(\n",
    "    df_orig=dat.tf, \n",
    "    df_R = dat.orig,\n",
    "    min =  tf$reduce_min(dat.tf, axis=0L),\n",
    "    max =  tf$reduce_max(dat.tf, axis=0L),\n",
    "    min = tf$constant(c(q1[1], q2[1], q3[1], q4[1]), dtype = 'float32'),\n",
    "    max = tf$constant(c(q1[2], q2[2], q3[2], q4[2]), dtype = 'float32'),\n",
    "    \n",
    "    # min = tf$constant(c(q1[1], q2[1], q3[1]), dtype = 'float32'),\n",
    "    # max = tf$constant(c(q1[2], q2[2], q3[2]), dtype = 'float32'),\n",
    "    type = c('o', 'c', 'c', 'o'),\n",
    "    A=A,\n",
    "    \n",
    "    #train\n",
    "    df_R_train = dat.train,\n",
    "    df_orig_train = dat.train.tf,\n",
    "    \n",
    "    \n",
    "    # df_orig_train_ct = dat.train.ct.tf,\n",
    "    # df_R_train_ct = dat.train.ct,\n",
    "    # \n",
    "    # df_orig_train_tx = dat.train.tx.tf,\n",
    "    # df_R_train_tx = dat.train.tx,\n",
    "    \n",
    "    #test\n",
    "    df_R_test = dat.test,\n",
    "    df_orig_test = dat.test.tf,\n",
    "    \n",
    "    # df_orig_test_ct = dat.test.ct.tf,\n",
    "    # df_R_test_ct = dat.test.ct,\n",
    "    # \n",
    "    # df_orig_test_tx = dat.test.tx.tf,\n",
    "    # df_R_test_tx = dat.test.tx,\n",
    "    # \n",
    "    #full\n",
    "    simulated_full_data = simulated_full_data,\n",
    "    simulated_data = simulated_data,\n",
    "    test.compl.data = test.compl.data,\n",
    "    dgp_params = list(\n",
    "      beta_0 = beta_0,\n",
    "      beta_t = beta_t,\n",
    "      beta_X = beta_X,\n",
    "      beta_TX = beta_TX\n",
    "    )\n",
    "  ))\n",
    "} \n",
    "\n",
    "\n",
    "#################################################\n",
    "# Benchmark (GLM T-learner)\n",
    "#################################################\n",
    "\n",
    "# functions for fitting model and plotting results\n",
    "\n",
    "fit.glm <- function(df, p) {\n",
    "  variable_names <- paste0(\"X\", 1:p)\n",
    "  form <- as.formula(paste(\"Y ~\", paste(variable_names, collapse = \" + \")))\n",
    "  \n",
    "  # Fit GLM for treatment and control groups\n",
    "  fit.dev.tx <- glm(form, data = df$data.dev.tx, family = binomial(link = \"logit\"))\n",
    "  fit.dev.ct <- glm(form, data = df$data.dev.ct, family = binomial(link = \"logit\"))\n",
    "  \n",
    "  # Predict outcome for observed T and X on derivation sample\n",
    "  df$data.dev$Y_pred <- predict(fit.dev.tx, newdata = df$data.dev, type = \"response\") * \n",
    "    df$data.dev$Tr + \n",
    "    predict(fit.dev.ct, newdata = df$data.dev, type = \"response\") * \n",
    "    (1 - df$data.dev$Tr)\n",
    "  \n",
    "  # Predict outcome for observed T and X on validation sample\n",
    "  df$data.val$Y_pred <- predict(fit.dev.tx, newdata = df$data.val, type = \"response\") * \n",
    "    df$data.val$Tr + \n",
    "    predict(fit.dev.ct, newdata = df$data.val, type = \"response\") * \n",
    "    (1 - df$data.val$Tr)\n",
    "  \n",
    "  # Predict ITE on derivation sample\n",
    "  pred.data.dev <- df$data.dev %>% dplyr::select(variable_names)\n",
    "  df$data.dev$Y_pred_tx <- predict(fit.dev.tx, newdata = pred.data.dev, type = \"response\") \n",
    "  df$data.dev$Y_pred_ct <- predict(fit.dev.ct, newdata = pred.data.dev, type = \"response\")\n",
    "  pred.dev <- df$data.dev$Y_pred_tx - df$data.dev$Y_pred_ct \n",
    "  \n",
    "  \n",
    "  # Predict ITE on validation sample\n",
    "  pred.data.val <- df$data.val %>% dplyr::select(variable_names)\n",
    "  df$data.val$Y_pred_tx <- predict(fit.dev.tx, newdata = pred.data.val, type = \"response\")\n",
    "  df$data.val$Y_pred_ct <- predict(fit.dev.ct, newdata = pred.data.val, type = \"response\")\n",
    "  pred.val <- df$data.val$Y_pred_tx  - df$data.val$Y_pred_ct \n",
    "  \n",
    "  # generate data\n",
    "  data.dev.rs <- df$data.dev %>% \n",
    "    mutate(ITE = pred.dev, RS = ifelse(ITE < 0, \"benefit\", \"harm\")) %>%\n",
    "    mutate(RS = as.factor(RS))\n",
    "  \n",
    "  data.val.rs <- df$data.val %>% \n",
    "    mutate(ITE = pred.val, RS = ifelse(ITE < 0, \"benefit\", \"harm\")) %>%\n",
    "    mutate(RS = as.factor(RS))\n",
    "  \n",
    "  \n",
    "  return(list(data.dev.rs = data.dev.rs, data.val.rs = data.val.rs, \n",
    "              model.dev.tx = fit.dev.tx, model.dev.ct = fit.dev.ct))\n",
    "  \n",
    "}\n",
    "\n",
    "\n",
    "library(gridExtra)\n",
    "plot_pred_ite <- function(model.results){\n",
    "  # train\n",
    "  p_dev_plot <- ggplot(model.results$data.dev.rs, aes(x = Y_prob, y = Y_pred, color = Treatment)) +\n",
    "    geom_point() +\n",
    "    geom_abline(slope = 1, intercept = 0, color = \"red\") +\n",
    "    labs(x = \"True Probabilities\", y = \"Estimated Probabilities\", title = \"Prob GLM (Train)\") +\n",
    "    theme_minimal() +\n",
    "    theme(legend.position = \"top\")\n",
    "  \n",
    "  # test\n",
    "  p_val_plot <- ggplot(model.results$data.val.rs, aes(x = Y_prob, y = Y_pred, color = Treatment)) +\n",
    "    geom_point() +\n",
    "    geom_abline(slope = 1, intercept = 0, color = \"red\") +\n",
    "    labs(x = \"True Probabilities\", y = \"Estimated Probabilities\", title = \"Prob GLM (Test)\") +\n",
    "    theme_minimal() +\n",
    "    theme(legend.position = \"top\")\n",
    "  \n",
    "  \n",
    "  \n",
    "  ite_dev_plot <- ggplot(model.results$data.dev.rs, aes(x=ITE_true, y=ITE, color=Treatment)) +\n",
    "    geom_point() +\n",
    "    geom_abline(slope = 1, intercept = 0, color = \"red\") +\n",
    "    labs(title = \"Training Data\", x = \"True ITE\", y = \"Estimated ITE\") +\n",
    "    theme_minimal() +\n",
    "    theme(legend.position = \"top\")\n",
    "  \n",
    "  ite_val_plot <- ggplot(model.results$data.val.rs, aes(x=ITE_true, y=ITE, color=Treatment)) +\n",
    "    geom_point() +\n",
    "    geom_abline(slope = 1, intercept = 0, color = \"red\") +\n",
    "    labs(title = \"Test Data\", x = \"True ITE\", y = \"Estimated ITE\") +\n",
    "    theme_minimal() +\n",
    "    theme(legend.position = \"top\")\n",
    "  \n",
    "  \n",
    "  grid.arrange(p_dev_plot, p_val_plot,\n",
    "               ite_dev_plot, ite_val_plot,\n",
    "               nrow = 2)\n",
    "}\n",
    "\n",
    "\n",
    "## new dgp\n",
    "\n",
    "##### DGP ########\n",
    "\n",
    "\n",
    "\n",
    "#### Model 1: no unnecessary variables, no confounder  ####\n",
    "\n",
    "dgp_model1 <-dgp_simulation(n_obs=20000, SEED=123,\n",
    "                beta_0 = 0.45,\n",
    "                beta_t = -0.85,\n",
    "                beta_X = c(-0.5, 0.1),\n",
    "                beta_TX = c(0.7),\n",
    "                p0 = 0, \n",
    "                confounder=FALSE, \n",
    "                drop=FALSE) # not yet specified\n",
    "\n",
    "\n",
    "glm.results1 <- fit.glm(dgp_model1$test.compl.data, p = 2)\n",
    "\n",
    "\n",
    "# plot the results\n",
    "plot_pred_ite(glm.results1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Model 2: 4 unnecessary variables, no confounder  ####\n",
    "\n",
    "dgp_model2 <-dgp_simulation(n_obs=20000, SEED=123,\n",
    "                            beta_0 = 0.45,\n",
    "                            beta_t = -0.85,\n",
    "                            beta_X = c(-0.5, 0.1),\n",
    "                            beta_TX = c(0.7),\n",
    "                            p0 = 4, \n",
    "                            confounder=FALSE, \n",
    "                            drop=FALSE) # not yet specified\n",
    "\n",
    "\n",
    "glm.results2 <- fit.glm(dgp_model2$test.compl.data, p = 6)\n",
    "\n",
    "\n",
    "# plot the results\n",
    "plot_pred_ite(glm.results2)\n",
    "\n",
    "\n",
    "\n",
    "#### Model 3: 4 unnecessary variables, 1 confounder  ####\n",
    "\n",
    "dgp_model3 <-dgp_simulation(n_obs=20000, SEED=123,\n",
    "                            beta_0 = 0.45,\n",
    "                            beta_t = -0.85,\n",
    "                            beta_X = c(-0.5, 0.1),\n",
    "                            beta_TX = c(0.7),\n",
    "                            p0 = 4, \n",
    "                            confounder=1, \n",
    "                            drop=FALSE) # not yet specified\n",
    "\n",
    "glm.results3 <- fit.glm(dgp_model3$test.compl.data, p = 6)\n",
    "\n",
    "\n",
    "# plot the results\n",
    "plot_pred_ite(glm.results3)\n",
    "\n",
    "\n",
    "#### Model 4: 4 unnecessary variables, 1 confounder, small treatment effect  ####\n",
    "\n",
    "dgp_model4 <-dgp_simulation(n_obs=20000, SEED=123,\n",
    "                            beta_0 = 0.45,\n",
    "                            beta_t = 0.02,        # small main effect\n",
    "                            beta_X = c(-0.5, 0.1),\n",
    "                            beta_TX = c(-0.01),   # small interaction effect\n",
    "                            p0 = 4, \n",
    "                            confounder=1, \n",
    "                            drop=FALSE) # not yet specified\n",
    "\n",
    "glm.results4 <- fit.glm(dgp_model4$test.compl.data, p = 6)\n",
    "\n",
    "\n",
    "# plot the results\n",
    "plot_pred_ite(glm.results4)\n",
    "\n",
    "\n",
    "### ate vs ite average prÃ¼fen\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# \n",
    "# #### Model 1: no unnecessary variables, no confounder  ####\n",
    "# \n",
    "# # specify number of predictor variables\n",
    "# p1 <- 2\n",
    "# # specify number of variables without effect\n",
    "# p0 <- 0\n",
    "# \n",
    "# dgp_data = dgp(n_obs, p=p1, p0=p0, SEED=123, confounder = FALSE)\n",
    "# # dataset including train and validation set (additional sets separated by treatment groups)\n",
    "# df <- dgp_data$test.compl.data\n",
    "# \n",
    "# str(df)\n",
    "# p <- p1 + p0 # number of variables\n",
    "# \n",
    "# glm.results <- fit.glm(df, p = p)\n",
    "# \n",
    "# # plot the results\n",
    "# plot_pred_ite(glm.results)\n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# #### 4 unnecessary variables, no confounder  ####\n",
    "# \n",
    "# \n",
    "# # specify number of predictor variables\n",
    "# p1 <- 2\n",
    "# # specify number of variables without effect\n",
    "# p0 <- 4\n",
    "# \n",
    "# dgp_data = dgp(n_obs, p=p1, p0=p0, SEED=123, confounder = FALSE)\n",
    "# # dataset including train and validation set (additional sets separated by treatment groups)\n",
    "# df <- dgp_data$test.compl.data\n",
    "# \n",
    "# str(df)\n",
    "# p <- p1 + p0 # number of variables\n",
    "# \n",
    "# \n",
    "# glm.results <- fit.glm(df, p = p)\n",
    "# \n",
    "# # plot the results\n",
    "# plot_pred_ite(glm.results)\n",
    "\n",
    "\n",
    "\n",
    "# \n",
    "# #### 4 unnecessary variables, 1 confounder  ####\n",
    "# \n",
    "# \n",
    "# # specify number of predictor variables\n",
    "# p1 <- 2\n",
    "# # specify number of variables without effect\n",
    "# p0 <- 4\n",
    "# \n",
    "# dgp_data = dgp(n_obs, p=p1, p0=p0, SEED=123, confounder = TRUE)\n",
    "# # dataset including train and validation set (additional sets separated by treatment groups)\n",
    "# df <- dgp_data$test.compl.data\n",
    "# \n",
    "# str(df)\n",
    "# p <- p1 + p0 # number of variables\n",
    "# \n",
    "# \n",
    "# glm.results <- fit.glm(df, p = p)\n",
    "# \n",
    "# # plot the results\n",
    "# plot_pred_ite(glm.results)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #### 4 unnecessary variables, no confounder, small treatment effect  ####\n",
    "# \n",
    "# \n",
    "# # specify number of predictor variables\n",
    "# p1 <- 2\n",
    "# # specify number of variables without effect\n",
    "# p0 <- 4\n",
    "# \n",
    "# dgp_data = dgp(n_obs, p=p1, p0=p0, SEED=123, confounder = FALSE, main_effect = 0.02,\n",
    "#                interaction_effect = -0.01)\n",
    "# # dataset including train and validation set (additional sets separated by treatment groups)\n",
    "# df <- dgp_data$test.compl.data\n",
    "# \n",
    "# str(df)\n",
    "# p <- p1 + p0 # number of variables\n",
    "# \n",
    "# \n",
    "# glm.results <- fit.glm(df, p = p)\n",
    "# \n",
    "# # plot the results\n",
    "# plot_pred_ite(glm.results)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### 4 unnecessary variables, 1 confounder, small treatment effect  ####\n",
    "\n",
    "\n",
    "# specify number of predictor variables\n",
    "# p1 <- 2\n",
    "# # specify number of variables without effect\n",
    "# p0 <- 4\n",
    "# \n",
    "# dgp_data = dgp(n_obs, p=p1, p0=p0, SEED=123, confounder = TRUE, main_effect = 0.02,\n",
    "#                interaction_effect = -0.01)\n",
    "# # dataset including train and validation set (additional sets separated by treatment groups)\n",
    "# df <- dgp_data$test.compl.data\n",
    "# \n",
    "# str(df)\n",
    "# p <- p1 + p0 # number of variables\n",
    "# \n",
    "# \n",
    "# glm.results <- fit.glm(df, p = p)\n",
    "# \n",
    "# \n",
    "# # plot the results\n",
    "# plot_pred_ite(glm.results)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#################################################\n",
    "# Complex Model (randomForest)\n",
    "#################################################\n",
    "\n",
    "\n",
    "library(randomForest)\n",
    "library(dplyr)\n",
    "\n",
    "fit.rf <- function(df, p, ntrees = 100) {\n",
    "  variable_names <- paste0(\"X\", 1:p)\n",
    "  form <- as.formula(paste(\"Y ~\", paste(variable_names, collapse = \" + \")))\n",
    "  \n",
    "  df$data.dev.tx$Y <- as.factor(df$data.dev.tx$Y)  # Ensure Y is a factor for classification\n",
    "  df$data.dev.ct$Y <- as.factor(df$data.dev.ct$Y)  # Ensure Y is a factor for classification\n",
    "  \n",
    "  # Fit random forest for treatment and control groups\n",
    "  fit.dev.tx <- randomForest(form, data = df$data.dev.tx, ntree = ntrees)\n",
    "  fit.dev.ct <- randomForest(form, data = df$data.dev.ct, ntree = ntrees)\n",
    "  \n",
    "  # Predict outcome for observed T and X on derivation sample\n",
    "  df$data.dev$Y_pred <- predict(fit.dev.tx, newdata = df$data.dev, type=\"prob\")[,2] * df$data.dev$Tr +\n",
    "    predict(fit.dev.ct, newdata = df$data.dev, type=\"prob\")[,2] * (1 - df$data.dev$Tr)\n",
    "  \n",
    "  # Predict outcome for observed T and X on validation sample\n",
    "  df$data.val$Y_pred <- predict(fit.dev.tx, newdata = df$data.val, type=\"prob\")[,2] * df$data.val$Tr +\n",
    "    predict(fit.dev.ct, newdata = df$data.val, type=\"prob\")[,2] * (1 - df$data.val$Tr)\n",
    "  \n",
    "  # Predict ITE on derivation sample\n",
    "  pred.data.dev <- df$data.dev %>% dplyr::select(variable_names)\n",
    "  df$data.dev$Y_pred_tx <- predict(fit.dev.tx, newdata = pred.data.dev, type=\"prob\")[,2]\n",
    "  df$data.dev$Y_pred_ct <- predict(fit.dev.ct, newdata = pred.data.dev, type=\"prob\")[,2]\n",
    "  pred.dev <- df$data.dev$Y_pred_tx - df$data.dev$Y_pred_ct\n",
    "  \n",
    "  # Predict ITE on validation sample\n",
    "  pred.data.val <- df$data.val %>% dplyr::select(variable_names)\n",
    "  df$data.val$Y_pred_tx <- predict(fit.dev.tx, newdata = pred.data.val, type=\"prob\")[,2]\n",
    "  df$data.val$Y_pred_ct <- predict(fit.dev.ct, newdata = pred.data.val, type=\"prob\")[,2]\n",
    "  pred.val <- df$data.val$Y_pred_tx - df$data.val$Y_pred_ct\n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  # check binary predictions on the train set\n",
    "  train_y_pred_tx <- predict(fit.dev.tx, newdata = df$data.dev.tx, type=\"response\")\n",
    "  train_y_pred_ct <- predict(fit.dev.ct, newdata = df$data.dev.ct, type=\"response\")\n",
    "  \n",
    "  mean(df$data.dev.tx$Y == train_y_pred_tx)\n",
    "  mean(df$data.dev.ct$Y == train_y_pred_ct)\n",
    "  # combined accuracy (train)\n",
    "  acc_train <- mean(c(df$data.dev.tx$Y == train_y_pred_tx, df$data.dev.ct$Y == train_y_pred_ct))\n",
    "  \n",
    "  \n",
    "  # check binary predictions on the validation set\n",
    "  val_y_pred_tx <- predict(fit.dev.tx, newdata = df$data.val.tx, type=\"response\")\n",
    "  val_y_pred_ct <- predict(fit.dev.ct, newdata = df$data.val.ct, type=\"response\")\n",
    "  \n",
    "  mean(df$data.val.tx$Y == val_y_pred_tx)\n",
    "  mean(df$data.val.ct$Y == val_y_pred_ct)\n",
    "  \n",
    "  # combined accuracy (validation)\n",
    "  acc_test <- mean(c(df$data.val.tx$Y == val_y_pred_tx, df$data.val.ct$Y == val_y_pred_ct))\n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  # Generate result sets\n",
    "  data.dev.rs <- df$data.dev %>%\n",
    "    mutate(ITE = pred.dev, RS = ifelse(ITE < 0, \"benefit\", \"harm\")) %>%\n",
    "    mutate(RS = as.factor(RS))\n",
    "  \n",
    "  data.val.rs <- df$data.val %>%\n",
    "    mutate(ITE = pred.val, RS = ifelse(ITE < 0, \"benefit\", \"harm\")) %>%\n",
    "    mutate(RS = as.factor(RS))\n",
    "  \n",
    "  # Print accuracy directly inside the function\n",
    "  cat(paste0(\"Train Accuracy: \", round(acc_train, 3), \n",
    "             \", Test Accuracy: \", round(acc_test, 3), \"\\n\"))\n",
    "  \n",
    "  \n",
    "  return(list(data.dev.rs = data.dev.rs, data.val.rs = data.val.rs,\n",
    "              model.dev.tx = fit.dev.tx, model.dev.ct = fit.dev.ct))\n",
    "}\n",
    "\n",
    "dgp_rf <-dgp_simulation(n_obs=20000, SEED=123,\n",
    "                            beta_0 = 0.45,\n",
    "                            beta_t = -0.85,\n",
    "                            beta_X = c(-5, 0.8),\n",
    "                            beta_TX = c(0.7),\n",
    "                            p0 = 0, \n",
    "                            confounder=FALSE, \n",
    "                            drop=FALSE) # not yet specified\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df <- dgp_rf$test.compl.data\n",
    "\n",
    "df$data.dev$Y <- as.factor(df$data.dev$Y)  # Ensure Y is a factor for classification\n",
    "randomForest(Y ~ Tr + X1 + X2, data = df$data.dev, ntree = ntrees)\n",
    "\n",
    "p <- 2 # number of variables\n",
    "rf.results <- fit.rf(df, p = p, ntrees = 100)\n",
    "\n",
    "# plot the results\n",
    "plot_pred_ite(rf.results)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dgp_rf <-dgp_simulation(n_obs=20000, SEED=123,\n",
    "                        beta_0 = 0.45,\n",
    "                        beta_t = -0.85,\n",
    "                        beta_X = c(-0.5, 0.8, 0.3, 0.6, -0.9),\n",
    "                        beta_TX = c(0.7, 0.3, -0.3),\n",
    "                        p0 = 0, \n",
    "                        confounder=FALSE, \n",
    "                        drop=FALSE) # not yet specified\n",
    "\n",
    "\n",
    "df <- dgp_rf$test.compl.data\n",
    "\n",
    "\n",
    "df$data.dev$Y <- as.factor(df$data.dev$Y)  # Ensure Y is a factor for classification\n",
    "randomForest(Y ~ Tr + X1 + X2, data = df$data.dev, ntree = ntrees)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dataset including train and validation set (additional sets separated by treatment groups)\n",
    "df <- dgp_data$test.compl.data\n",
    "str(df)\n",
    "p <- 2 # number of variables\n",
    "\n",
    "rf.results <- fit.rf(df, p = p, ntrees = 100)\n",
    "\n",
    "# plot the results\n",
    "plot_pred_ite(rf.results)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#################################################\n",
    "# Complex Model (Random Forest comets package, tuned)\n",
    "#################################################\n",
    "\n",
    "# dataset including train and validation set (additional sets separated by treatment groups)\n",
    "df <- dgp_data$test.compl.data\n",
    "str(df)\n",
    "p <- 2 # number of variables\n",
    "library(comets)\n",
    "library(dplyr)\n",
    "?comets:::tuned_rf\n",
    "# extract the tuned_rf function\n",
    "comets_tuned_rf <- comets:::tuned_rf\n",
    "\n",
    "fit.tuned_rf <- function(df, p) {\n",
    "  variable_names <- paste0(\"X\", 1:p)\n",
    "  form <- as.formula(paste(\"Y ~\", paste(variable_names, collapse = \" + \")))\n",
    "  \n",
    "  df$data.dev.tx$Y <- as.factor(df$data.dev.tx$Y)  # Ensure Y is a factor for classification\n",
    "  df$data.dev.ct$Y <- as.factor(df$data.dev.ct$Y)  # Ensure Y is a factor for classification\n",
    "  \n",
    "  # Fit random forest for treatment and control groups\n",
    "  fit.dev.tx <- comets_tuned_rf(y=as.matrix(df$data.dev.tx$Y), x=as.matrix(df$data.dev.tx %>% dplyr::select(variable_names)))\n",
    "  fit.dev.ct <- comets_tuned_rf(y=as.matrix(df$data.dev.ct$Y), x=as.matrix(df$data.dev.ct %>% dplyr::select(variable_names)))\n",
    "  \n",
    "  # Feature set of derivation sample\n",
    "  X_dev <- as.matrix(df$data.dev %>% dplyr::select(variable_names))\n",
    "  \n",
    "  # Predict probabilities on derivation sample\n",
    "  pred_tx_dev <- predict(fit.dev.tx, data = X_dev)\n",
    "  pred_ct_dev <- predict(fit.dev.ct, data = X_dev)\n",
    "  \n",
    "  # Predict outcome for observed T and X on derivation sample\n",
    "  df$data.dev$Y_pred <- pred_tx_dev * df$data.dev$Tr + pred_ct_dev * (1 - df$data.dev$Tr)\n",
    "  \n",
    "  # Predict ITE on derivation sample\n",
    "  df$data.dev$Y_pred_tx <- pred_tx_dev\n",
    "  df$data.dev$Y_pred_ct <- pred_ct_dev\n",
    "  pred.dev <- df$data.dev$Y_pred_tx - df$data.dev$Y_pred_ct\n",
    "  \n",
    "  \n",
    "  # Feature set of validation sample\n",
    "  X_val <- as.matrix(df$data.val %>% dplyr::select(variable_names))\n",
    "  \n",
    "  # Predict probabilities on derivation sample\n",
    "  pred_tx_val <- predict(fit.dev.tx, data = X_val)\n",
    "  pred_ct_val <- predict(fit.dev.ct, data = X_val)\n",
    "  \n",
    "  # Predict outcome for observed T and X on validation sample\n",
    "  df$data.val$Y_pred <- pred_tx_val * df$data.val$Tr + pred_ct_val * (1 - df$data.val$Tr)\n",
    "  \n",
    "  # Predict ITE on validation sample\n",
    "  df$data.val$Y_pred_tx <- pred_tx_val\n",
    "  df$data.val$Y_pred_ct <- pred_ct_val\n",
    "  pred.val <- df$data.val$Y_pred_tx - df$data.val$Y_pred_ct\n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  # check binary predictions on the train set\n",
    "  # train_y_pred_tx <- predict(fit.dev.tx, newdata = df$data.dev.tx, type=\"response\")\n",
    "  # train_y_pred_ct <- predict(fit.dev.ct, newdata = df$data.dev.ct, type=\"response\")\n",
    "  \n",
    "  # mean(df$data.dev.tx$Y == train_y_pred_tx)\n",
    "  # mean(df$data.dev.ct$Y == train_y_pred_ct)\n",
    "  # # combined accuracy (train)\n",
    "  # acc_train <- mean(c(df$data.dev.tx$Y == train_y_pred_tx, df$data.dev.ct$Y == train_y_pred_ct))\n",
    "  \n",
    "  \n",
    "  # check binary predictions on the validation set\n",
    "  # val_y_pred_tx <- predict(fit.dev.tx, newdata = df$data.val.tx, type=\"response\")\n",
    "  # val_y_pred_ct <- predict(fit.dev.ct, newdata = df$data.val.ct, type=\"response\")\n",
    "  # \n",
    "  # mean(df$data.val.tx$Y == val_y_pred_tx)\n",
    "  # mean(df$data.val.ct$Y == val_y_pred_ct)\n",
    "  # \n",
    "  # combined accuracy (validation)\n",
    "  # acc_test <- mean(c(df$data.val.tx$Y == val_y_pred_tx, df$data.val.ct$Y == val_y_pred_ct))\n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  # Generate result sets\n",
    "  data.dev.rs <- df$data.dev %>%\n",
    "    mutate(ITE = pred.dev, RS = ifelse(ITE < 0, \"benefit\", \"harm\")) %>%\n",
    "    mutate(RS = as.factor(RS))\n",
    "  \n",
    "  data.val.rs <- df$data.val %>%\n",
    "    mutate(ITE = pred.val, RS = ifelse(ITE < 0, \"benefit\", \"harm\")) %>%\n",
    "    mutate(RS = as.factor(RS))\n",
    "  \n",
    "  # Print accuracy directly inside the function\n",
    "  # cat(paste0(\"Train Accuracy: \", round(acc_train, 3), \n",
    "  #            \", Test Accuracy: \", round(acc_test, 3), \"\\n\"))\n",
    "  # \n",
    "  \n",
    "  return(list(data.dev.rs = data.dev.rs, data.val.rs = data.val.rs,\n",
    "              model.dev.tx = fit.dev.tx, model.dev.ct = fit.dev.ct))\n",
    "}\n",
    "\n",
    "\n",
    "dgp_tuned_rf <-dgp_simulation(n_obs=20000, SEED=123,\n",
    "                        beta_0 = 0.45,\n",
    "                        beta_t = -0.85,\n",
    "                        beta_X = c(-0.5, 0.8),\n",
    "                        beta_TX = c(0.7),\n",
    "                        p0 = 0, \n",
    "                        confounder=FALSE, \n",
    "                        drop=FALSE) # not yet specified\n",
    "\n",
    "df <- dgp_tuned_rf$test.compl.data\n",
    "\n",
    "\n",
    "tuned_rf.results <- fit.tuned_rf(df, p = p)\n",
    "\n",
    "\n",
    "# plot the results\n",
    "plot_pred_ite(tuned_rf.results)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## plots with Outcome group colored:\n",
    "\n",
    "# train\n",
    "ggplot(rf.results$data.dev.rs, aes(x = Y_prob, y = Y_pred, color = as.factor(Y))) +\n",
    "  geom_point() +\n",
    "  geom_abline(slope = 1, intercept = 0, color = \"red\") +\n",
    "  labs(x = \"True Probabilities\", y = \"Estimated Probabilities\", title = \"Prob GLM (Train)\") +\n",
    "  theme_minimal() +\n",
    "  theme(legend.position = \"top\")\n",
    "\n",
    "# test\n",
    "ggplot(rf.results$data.val, aes(x = Y_prob, y = Y_pred, color = as.factor(Y))) +\n",
    "  geom_point() +\n",
    "  geom_abline(slope = 1, intercept = 0, color = \"red\") +\n",
    "  labs(x = \"True Probabilities\", y = \"Estimated Probabilities\", title = \"Prob GLM (Test)\") +\n",
    "  theme_minimal() +\n",
    "  theme(legend.position = \"top\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#################################################\n",
    "# Analysis as Holly T-learner GLM\n",
    "#################################################\n",
    "\n",
    "\n",
    "dgp_data$simulated_full_data %>% ggplot(aes(x=ITE_true)) +\n",
    "  geom_density(color=\"gray8\",fill=\"skyblue\",alpha=.6) + \n",
    "  theme_minimal() + \n",
    "  xlab(\"True ITE\") + \n",
    "  geom_vline(xintercept = 0, linetype=\"dashed\") + coord_cartesian(xlim = c(-.8,.6))\n",
    "\n",
    "str(dgp_data$simulated_data)\n",
    "\n",
    "# average treatment effects\n",
    "mean(dgp_data$simulated_full_data$ITE_true)\n",
    "\n",
    "# percentage of patients with Y=1\n",
    "mean(dgp_data$simulated_data$Y)\n",
    "\n",
    "\n",
    "# Calculate ITE with logistic T-learner\n",
    "test.results <- logis.ITE(dgp_data$test.compl.data , p=2)\n",
    "\n",
    "\n",
    "data.dev.rs = test.results[[\"data.dev.rs\"]] %>%  as.data.frame()\n",
    "data.val.rs = test.results[[\"data.val.rs\"]] %>%  as.data.frame()\n",
    "\n",
    "library(ggpubr)\n",
    "plot_outcome_ITE(data.dev.rs = data.dev.rs, data.val.rs = data.val.rs, x_lim = c(-0.8,0.8))\n",
    "\n",
    "\n",
    "plot_ITE_density(test.results = test.results, true.data = dgp_data$simulated_full_data)\n",
    "\n",
    "\n",
    "plot_ITE_density_tx_ct(data = data.dev.rs)\n",
    "plot_ITE_density_tx_ct(data = data.val.rs)\n",
    "\n",
    "par(mfrow=c(1,2))\n",
    "plot(ITE ~ ITE_true, data = data.dev.rs, col = \"orange\", pch = 19, cex = 0.5\n",
    "     , main = \"Training Data\")\n",
    "abline(0,1)\n",
    "plot(ITE ~ ITE_true, data = data.val.rs, col = \"#36648B\", pch = 19, cex = 0.5\n",
    "     , main = \"Test Data\")\n",
    "abline(0,1)\n",
    "\n",
    "\n",
    "ggplot(data.dev.rs, aes(x=ITE_true, y=ITE, color=Treatment)) +\n",
    "  geom_point() +\n",
    "  geom_abline(slope = 1, intercept = 0, color = \"red\") +\n",
    "  labs(title = \"Training Data\", x = \"True ITE\", y = \"Estimated ITE\") +\n",
    "  theme_minimal() +\n",
    "  theme(legend.position = \"top\")\n",
    "\n",
    "ggplot(data.val.rs, aes(x=ITE_true, y=ITE, color=Treatment)) +\n",
    "  geom_point() +\n",
    "  geom_abline(slope = 1, intercept = 0, color = \"red\") +\n",
    "  labs(title = \"Test Data\", x = \"True ITE\", y = \"Estimated ITE\") +\n",
    "  theme_minimal() +\n",
    "  theme(legend.position = \"top\")\n",
    "\n",
    "\n",
    "\n",
    "# compare estimated ITE and true ITE\n",
    "mean(abs(data.dev.rs$ITE_true - data.dev.rs$ITE))\n",
    "mean(abs(data.val.rs$ITE_true - data.val.rs$ITE))\n",
    "\n",
    "\n",
    "\n",
    "breaks <- c(-0.75, -0.4, -0.2, 0.1, 0.5)\n",
    "log.odds <- F\n",
    "data.dev.grouped.ATE <- data.dev.rs %>% \n",
    "  mutate(ITE.Group = cut(ITE, breaks = breaks, include.lowest = T)) %>%\n",
    "  dplyr::filter(!is.na(ITE.Group)) %>%\n",
    "  group_by(ITE.Group) %>% \n",
    "  group_modify(~ calc.ATE.Odds(.x, log.odds = log.odds)) %>% ungroup()\n",
    "data.val.grouped.ATE <- data.val.rs %>% \n",
    "  mutate(ITE.Group = cut(ITE, breaks = breaks, include.lowest = T)) %>%\n",
    "  dplyr::filter(!is.na(ITE.Group)) %>%\n",
    "  group_by(ITE.Group) %>%\n",
    "  group_modify(~ calc.ATE.Odds(.x, log.odds = log.odds)) %>% ungroup() \n",
    "\n",
    "plot_ATE_ITE_in_group(dev.data = data.dev.grouped.ATE, val.data = data.val.grouped.ATE, \n",
    "                      log.odds = log.odds, ylb = 0, yub = 4,\n",
    "                      train.data.name = \"Train\", test.data.name = \"Test\")\n",
    "\n",
    "\n",
    "\n",
    "# average treatment effects\n",
    "mean(dgp_data$simulated_full_data$ITE_true)\n",
    "\n",
    "mean(data.dev.rs$ITE_true)\n",
    "mean(data.val.rs$ITE_true)\n",
    "\n",
    "\n",
    "mean(data.dev.rs$ITE)\n",
    "mean(data.val.rs$ITE)\n",
    "\n",
    "# calcualte ATE\n",
    "df <- dgp_data$simulated_full_data\n",
    "mean(df$Y[df$Treatment == 1]) - mean(df$Y[df$Treatment == 0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# save results for later\n",
    "test.results.glm <- logis.ITE(dgp_data$test.compl.data , p=2)\n",
    "\n",
    "\n",
    "data.dev.rs.glm = test.results[[\"data.dev.rs\"]] %>%  as.data.frame()\n",
    "data.val.rs.glm = test.results[[\"data.val.rs\"]] %>%  as.data.frame()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#################################################\n",
    "# fit TRAM-DAG wit CS(T, X1) \n",
    "#################################################\n",
    "\n",
    "(global_min = dgp_data$min)\n",
    "(global_max = dgp_data$max)\n",
    "data_type = dgp_data$type\n",
    "\n",
    "# len_theta_max = len_theta\n",
    "# for (i in 1:nrow(MA)){ #Maximum number of coefficients (BS and Levels - 1 for the ordinal)\n",
    "#   if (dgp_data$type[i] == 'o'){\n",
    "#     len_theta_max = max(len_theta_max, nlevels(dgp_data$df_R[,i]) - 1)\n",
    "#   }\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "##### Train on control group ####\n",
    "\n",
    "param_model = create_param_model(MA, hidden_features_I=hidden_features_I, len_theta=len_theta, hidden_features_CS=hidden_features_CS)\n",
    "optimizer = optimizer_adam(learning_rate = 0.0005)\n",
    "param_model$compile(optimizer, loss=struct_dag_loss)\n",
    "\n",
    "h_params <- param_model(dgp_data$df_orig_train)\n",
    "\n",
    "param_model$evaluate(x = dgp_data$df_orig_train, y=dgp_data$df_orig_train, batch_size = 7L)\n",
    "summary(param_model)\n",
    "\n",
    "# show activation function activation_68 --> Relu is used (before it was sigmoid)\n",
    "param_model$get_layer(\"activation_48\")$get_config()\n",
    "\n",
    "##### Training ####\n",
    "\n",
    "# num_epochs <- 1000\n",
    "num_epochs <- 450   ### final model with c(2,5,5,2) and Relu\n",
    "# fnh5 = paste0(fn, '_E', num_epochs, '.h5')\n",
    "# fnRdata = paste0(fn, '_E', num_epochs, '.RData')\n",
    "\n",
    "fnh5 = paste0(fn, '_E', num_epochs, 'CS.h5')   # 'CI.h5'\n",
    "fnRdata = paste0(fn, '_E', num_epochs, 'CS.RData')   # 'CI.RData'\n",
    "if (file.exists(fnh5)){\n",
    "  param_model$load_weights(fnh5)\n",
    "  load(fnRdata) #Loading of the workspace causes trouble e.g. param_model is zero\n",
    "  # Quick Fix since loading global_min causes problem (no tensors as RDS)\n",
    "  (global_min = dgp_data$min)\n",
    "  (global_max = dgp_data$max)\n",
    "} else {\n",
    "  if (FALSE){ ### Full Training w/o diagnostics\n",
    "    hist = param_model$fit(x = dgp_data$df_orig_train, y=dgp_data$df_orig_train, epochs = 200L,verbose = TRUE)\n",
    "    param_model$save_weights(fn)\n",
    "    plot(hist$epoch, hist$history$loss)\n",
    "    plot(hist$epoch, hist$history$loss, ylim=c(1.07, 1.2))\n",
    "  } else { ### Training with diagnostics\n",
    "    # ws <- data.frame(w12 = numeric())\n",
    "    # ws <- data.frame(w34 = numeric())\n",
    "    train_loss <- numeric()\n",
    "    val_loss <- numeric()\n",
    "    \n",
    "    # Training loop\n",
    "    for (e in 1:num_epochs) {\n",
    "      print(paste(\"Epoch\", e))\n",
    "      hist <- param_model$fit(x = dgp_data$df_orig_train, y = dgp_data$df_orig_train, \n",
    "                              epochs = 1L, verbose = TRUE, \n",
    "                              validation_data = list(dgp_data$df_orig_test, dgp_data$df_orig_test))\n",
    "      \n",
    "      # Append losses to history\n",
    "      train_loss <- c(train_loss, hist$history$loss)\n",
    "      val_loss <- c(val_loss, hist$history$val_loss)\n",
    "      \n",
    "      # Extract specific weights\n",
    "      # w <- param_model$get_layer(name = \"beta\")$get_weights()[[1]]\n",
    "      \n",
    "      # ws <- rbind(ws, data.frame(w34 = w[3,4]))\n",
    "    }\n",
    "    # Save the model\n",
    "    param_model$save_weights(fnh5)\n",
    "    save(train_loss, val_loss, train_loss, f, MA, len_theta,\n",
    "         hidden_features_I,\n",
    "         hidden_features_CS,\n",
    "         # ws,\n",
    "         #global_min, global_max,\n",
    "         file = fnRdata)\n",
    "  }\n",
    "}\n",
    "\n",
    "par(mfrow=c(1,1))\n",
    "epochs = length(train_loss)\n",
    "plot(1:length(train_loss), train_loss, type='l', main='Normal Training (green is valid)', ylim = c(2.7, 2.8))\n",
    "lines(1:length(train_loss), val_loss, type = 'l', col = 'green')\n",
    "\n",
    "# Last 50\n",
    "diff = max(epochs - 100,0)\n",
    "plot(diff:epochs, val_loss[diff:epochs], type = 'l', col = 'green', main='Last 50 epochs')\n",
    "lines(diff:epochs, train_loss[diff:epochs], type='l')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# learned weights for linear Shift\n",
    "param_model$get_layer(name = \"beta\")$get_weights()[[1]] * param_model$get_layer(name = \"beta\")$mask\n",
    "\n",
    "# Weight estimates by glm()\n",
    "# fit_321 <- glm(x3 ~ x1 + x2, data = dgp_data$df_R_train_ct, family = binomial(link=\"logit\")) # glm for binary (negative shift)\n",
    "\n",
    "\n",
    "p <- ggplot(ws, aes(x=1:nrow(ws))) + \n",
    "  geom_line(aes(y=w34, color='x2 --> Y')) + \n",
    "  # geom_line(aes(y=w23, color='x2 --> x3')) + \n",
    "  # geom_hline(aes(yintercept=-coef(fit_321)[2], color='glm'), linetype=2) +\n",
    "  # geom_hline(aes(yintercept=-coef(fit_321)[3], color='glm'), linetype=2) +\n",
    "  #scale_color_manual(values=c('x1 --> x2'='skyblue', 'x1 --> x3='red', 'x2 --> x3'='darkgreen')) +\n",
    "  labs(x='Epoch', y='Coefficients') +\n",
    "  theme_minimal() +\n",
    "  theme(legend.title = element_blank())  # Removes the legend title\n",
    "\n",
    "p\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#################################################\n",
    "# calculate ITE_i for train and test set\n",
    "#################################################\n",
    "\n",
    "\n",
    "\n",
    "do_probability = function (h_params){\n",
    "  #t_i = intervention_0_tf # (40000, 3)    # original data x1, x2, x3 for each obs\n",
    "  #h_params = h_params_ct                 # NN outputs (CS, LS, theta') for each obs\n",
    "  k_min <- k_constant(global_min)\n",
    "  k_max <- k_constant(global_max)\n",
    "  \n",
    "  # from the last dimension of h_params the first entry is h_cs1\n",
    "  # the second to |X|+1 are the LS\n",
    "  # the 2+|X|+1 to the end is H_I\n",
    "  \n",
    "  # complex shifts for each observation\n",
    "  h_cs <- h_params[,,1, drop = FALSE]\n",
    "  \n",
    "  # linear shifts for each observation\n",
    "  h_ls <- h_params[,,2, drop = FALSE]\n",
    "  #LS\n",
    "  h_LS = tf$squeeze(h_ls, axis=-1L) # throw away last dimension\n",
    "  #CS\n",
    "  h_CS = tf$squeeze(h_cs, axis=-1L)\n",
    "  theta_tilde <- h_params[,,3:dim(h_params)[3], drop = FALSE]\n",
    "  #Thetas for intercept (bernstein polynomials?) -> to_theta3 to make them increasing\n",
    "  theta = to_theta3(theta_tilde)\n",
    "  \n",
    "  if (!exists('data_type')){ #Defaulting to all continuous \n",
    "    cont_dims = 1:dim(theta_tilde)[2]\n",
    "    cont_ord = c()\n",
    "  } else{ \n",
    "    cont_dims = which(data_type == 'c')\n",
    "    cont_ord = which(data_type == 'o')\n",
    "  }\n",
    "  if (len_theta == -1){ \n",
    "    len_theta = dim(theta_tilde)[3]\n",
    "  }\n",
    "  \n",
    "  # NLL = 0\n",
    "  ### Continiuous dimensions\n",
    "  #### At least one continuous dimension exits\n",
    "  # if (length(cont_dims) != 0){\n",
    "  #   \n",
    "  #   # inputs in h_dag_extra:\n",
    "  #   # data=(40000, 3), \n",
    "  #   # theta=(40000, 3, 20), k_min=(3), k_max=(3))\n",
    "  #   \n",
    "  #   # creates the value of the Bernstein at each observation\n",
    "  #   # and current parameters: output shape=(40000, 3)\n",
    "  #   h_I = h_dag_extra(t_i[,cont_dims, drop=FALSE], theta[,cont_dims,1:len_theta,drop=FALSE], k_min[cont_dims], k_max[cont_dims]) \n",
    "  #   \n",
    "  #   # adding the intercepts and shifts: results in shape=(40000, 3)\n",
    "  #   # basically the estimated value of the latent variable\n",
    "  #   h = h_I + h_LS[,cont_dims, drop=FALSE] + h_CS[,cont_dims, drop=FALSE]\n",
    "  #   \n",
    "  #   #Compute terms for change of variable formula\n",
    "  #   \n",
    "  #   # log of standard logistic density at h\n",
    "  #   log_latent_density = -h - 2 * tf$math$softplus(-h) #log of logistic density at h\n",
    "  #   \n",
    "  #   ## h' dh/dtarget is 0 for all shift terms\n",
    "  #   log_hdash = tf$math$log(tf$math$abs(\n",
    "  #     h_dag_dash_extra(t_i[,cont_dims, drop=FALSE], theta[,cont_dims,1:len_theta,drop=FALSE], k_min[cont_dims], k_max[cont_dims]))\n",
    "  #   ) - \n",
    "  #     tf$math$log(k_max[cont_dims] - k_min[cont_dims])  #Chain rule! See Hathorn page 12 \n",
    "  #   \n",
    "  #   NLL = NLL - tf$reduce_mean(log_latent_density + log_hdash)\n",
    "  # }\n",
    "  \n",
    "  ### Ordinal dimensions\n",
    "  if (length(cont_ord) != 0){\n",
    "    B = dim(h_params)[1]\n",
    "    for (col in cont_ord){\n",
    "      # col=3\n",
    "      nol = tf$cast(k_max[col] - 1L, tf$int32) # Number of cut-points in respective dimension\n",
    "      theta_ord = theta[,col,1:nol,drop=TRUE] # Intercept (2 values per observation if 2 cutpoints)\n",
    "      \n",
    "      \n",
    "      h = theta_ord + h_LS[,col, drop=FALSE] + h_CS[,col, drop=FALSE]\n",
    "      \n",
    "      cdf_cut <- logistic_cdf(h)\n",
    "      prob_Y1_X <- 1- cdf_cut\n",
    "      # # putting -Inf and +Inf to the left and right of the cutpoints\n",
    "      # neg_inf = tf$fill(c(B,1L), -Inf)\n",
    "      # pos_inf = tf$fill(c(B,1L), +Inf)\n",
    "      # h_with_inf = tf$concat(list(neg_inf, h, pos_inf), axis=-1L)\n",
    "      # logistic_cdf_values = logistic_cdf(h_with_inf)\n",
    "      # #cdf_diffs <- tf$subtract(logistic_cdf_values[, 2:ncol(logistic_cdf_values)], logistic_cdf_values[, 1:(ncol(logistic_cdf_values) - 1)])\n",
    "      # cdf_diffs <- tf$subtract(logistic_cdf_values[, 2:tf$shape(logistic_cdf_values)[2]], logistic_cdf_values[, 1:(tf$shape(logistic_cdf_values)[2] - 1)])\n",
    "      # \n",
    "      # # Picking the observed cdf_diff entry for column 4:\n",
    "      # class_indices <- tf$cast(t_i[, col] - 1, tf$int32)  # Convert to zero-based index\n",
    "      # # Create batch indices to pair with class indices\n",
    "      # batch_indices <- tf$range(tf$shape(class_indices)[1])\n",
    "      # # Combine batch_indices and class_indices into pairs of indices\n",
    "      # gather_indices <- tf$stack(list(batch_indices, class_indices), axis=1)\n",
    "      # cdf_diff_picked <- tf$gather_nd(cdf_diffs, gather_indices)\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  ### DEBUG \n",
    "  #if (sum(is.infinite(log_lik$numpy())) > 0){\n",
    "  #  print(\"Hall\")\n",
    "  #}\n",
    "  return (prob_Y1_X)\n",
    "}\n",
    "\n",
    "\n",
    "### Training set\n",
    "\n",
    "# Treatment = 0\n",
    "\n",
    "# set the values of the first column of dgp_data$df_R_train to 0 and add 1 to the last column\n",
    "train_df_T0 <- dgp_data$df_R_train %>%\n",
    "  mutate(\n",
    "    # x1 = 0,  # Set the first column (x1) to 0\n",
    "    x1 = 1, # indicating level 0 control\n",
    "    x4 = x4 + 1 # Add 1 to the last column (x4)\n",
    "  )\n",
    "\n",
    "# convert to tensor\n",
    "train_tf_T0 <- tf$constant(as.matrix(train_df_T0), dtype = 'float32')\n",
    "\n",
    "# outputs for T=0 on the train set\n",
    "h_params_ct <- param_model(train_tf_T0)\n",
    "\n",
    "\n",
    "\n",
    "# Treatment = 1\n",
    "# set the values of the first column of dgp_data$df_R_train to 1 and add 1 to the last column\n",
    "train_df_T1 <- dgp_data$df_R_train %>%\n",
    "  mutate(\n",
    "    # x1 = 1,  # Set the first column (x1) to 1\n",
    "    x1 = 2,  # indicating level 1 treatment\n",
    "    x4 = x4 + 1 # Add 1 to the last column (x4)\n",
    "  )\n",
    "# convert to tensor\n",
    "train_tf_T1 <- tf$constant(as.matrix(train_df_T1), dtype = 'float32')\n",
    "# outputs for T=1 on the train set\n",
    "h_params_tx <- param_model(train_tf_T1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Y0 <- do_probability(h_params_ct)\n",
    "\n",
    "Y1 <- do_probability(h_params_tx)\n",
    "\n",
    "\n",
    "ITE_i_train <- Y1 - Y0\n",
    "\n",
    "\n",
    "ITE_true <- dgp_data$test.compl.data$data.dev$ITE_true\n",
    "\n",
    "plot(ITE_true, ITE_i_train, xlab = \"True ITE\", ylab = \"Estimated ITE TRAM-DAG\", main = \"ITE_i\")\n",
    "abline(0,1)\n",
    "\n",
    "\n",
    "\n",
    "### Test set\n",
    "\n",
    "# Treatment = 0\n",
    "\n",
    "# set the values of the first column of dgp_data$df_R_test to 0 and add 1 to the last column\n",
    "test_df_T0 <- dgp_data$df_R_test %>%\n",
    "  mutate(\n",
    "    # x1 = 0,  # Set the first column (x1) to 0\n",
    "    x1 = 1, # indicating level 0 control\n",
    "    x4 = x4 + 1 # Add 1 to the last column (x4)\n",
    "  )\n",
    "# convert to tensor\n",
    "test_tf_T0 <- tf$constant(as.matrix(test_df_T0), dtype = 'float32')\n",
    "# outputs for T=0 on the test set\n",
    "h_params_ct <- param_model(test_tf_T0)\n",
    "\n",
    "# Treatment = 1\n",
    "\n",
    "# set the values of the first column of dgp_data$df_R_test to 1 and add 1 to the last column\n",
    "test_df_T1 <- dgp_data$df_R_test %>%\n",
    "  mutate(\n",
    "    # x1 = 1,  # Set the first column (x1) to 1\n",
    "    x1 = 2,  # indicating level 1 treatment\n",
    "    x4 = x4 + 1 # Add 1 to the last column (x4)\n",
    "  )\n",
    "# convert to tensor\n",
    "test_tf_T1 <- tf$constant(as.matrix(test_df_T1), dtype = 'float32')\n",
    "# outputs for T=1 on the test set\n",
    "h_params_tx <- param_model(test_tf_T1)\n",
    "\n",
    "\n",
    "Y0 <- do_probability(h_params_ct)\n",
    "\n",
    "Y1 <- do_probability(h_params_tx)\n",
    "\n",
    "\n",
    "ITE_i_test <- Y1 - Y0\n",
    "\n",
    "\n",
    "ITE_true <- dgp_data$test.compl.data$data.val$ITE_true\n",
    "\n",
    "plot(ITE_true, ITE_i_test, xlab = \"True ITE\", ylab = \"Estimated ITE TRAM-DAG\", main = \"ITE_i\")\n",
    "abline(0,1)\n",
    "\n",
    "\n",
    "\n",
    "#################################################\n",
    "# Analysis as Holly T-learner (TRAM-DAG)\n",
    "#################################################\n",
    "\n",
    "# combine results from TRAM-DAG to the Holly-GLM and the true data\n",
    "\n",
    "#train\n",
    "test.results$data.dev.rs$ITE <- as.numeric(ITE_i_train)\n",
    "test.results$data.dev.rs$RS <- ifelse(test.results$data.dev.rs$ITE > 0, \"harm\", \"benefit\")\n",
    "\n",
    "#test\n",
    "test.results$data.val.rs$ITE <- as.numeric(ITE_i_test)\n",
    "test.results$data.val.rs$RS <- ifelse(test.results$data.val.rs$ITE > 0, \"harm\", \"benefit\")\n",
    "\n",
    "# \n",
    "# test.results$data.dev.rs\n",
    "# # Calculate ITE with logistic T-learner\n",
    "test.results.glm <- logis.ITE(dgp_data$test.compl.data , p=2)\n",
    "\n",
    "\n",
    "# plot the estimated ITE of the glm and TRAM-DAG: They are almost exactly the same as expected:\n",
    "par(mfrow=c(1,2))\n",
    "plot(test.results.glm$data.dev.rs$ITE, ITE_i_train, xlab = \"ITE_i glm\", ylab = \"ITE_i TRAM-DAG\", main = \"ITE_i Train\")\n",
    "abline(0,1)\n",
    "plot(test.results.glm$data.val.rs$ITE, ITE_i_test, xlab = \"ITE_i glm\", ylab = \"ITE_i TRAM-DAG\", main = \"ITE_i Test\")\n",
    "abline(0,1)\n",
    "\n",
    "\n",
    "data.dev.rs = test.results[[\"data.dev.rs\"]] %>%  as.data.frame()\n",
    "data.val.rs = test.results[[\"data.val.rs\"]] %>%  as.data.frame()\n",
    "\n",
    "library(ggpubr)\n",
    "plot_outcome_ITE(data.dev.rs = data.dev.rs, data.val.rs = data.val.rs, x_lim = c(-0.8,0.8))\n",
    "\n",
    "\n",
    "plot_ITE_density(test.results = test.results,true.data = dgp_data$simulated_full_data)\n",
    "\n",
    "\n",
    "plot_ITE_density_tx_ct(data = data.dev.rs)\n",
    "plot_ITE_density_tx_ct(data = data.val.rs)\n",
    "\n",
    "par(mfrow=c(1,2))\n",
    "plot(ITE ~ ITE_true, data = data.dev.rs, col = \"orange\", pch = 19, cex = 0.5,\n",
    "     main = \"Training Data\")\n",
    "abline(0,1)\n",
    "plot(ITE ~ ITE_true, data = data.val.rs, col = \"#36648B\", pch = 19, cex = 0.5,\n",
    "     main = \"Test Data\")\n",
    "abline(0,1)\n",
    "\n",
    "\n",
    "# compare estimated ITE and true ITE\n",
    "mean(abs(data.dev.rs$ITE_true - data.dev.rs$ITE))\n",
    "mean(abs(data.val.rs$ITE_true - data.val.rs$ITE))\n",
    "\n",
    "\n",
    "breaks <- c(-0.75, -0.4, -0.2, 0.1, 0.5)\n",
    "log.odds <- F\n",
    "data.dev.grouped.ATE <- data.dev.rs %>% \n",
    "  mutate(ITE.Group = cut(ITE, breaks = breaks, include.lowest = T)) %>%\n",
    "  dplyr::filter(!is.na(ITE.Group)) %>%\n",
    "  group_by(ITE.Group) %>% \n",
    "  group_modify(~ calc.ATE.Odds(.x, log.odds = log.odds)) %>% ungroup()\n",
    "data.val.grouped.ATE <- data.val.rs %>% \n",
    "  mutate(ITE.Group = cut(ITE, breaks = breaks, include.lowest = T)) %>%\n",
    "  dplyr::filter(!is.na(ITE.Group)) %>%\n",
    "  group_by(ITE.Group) %>%\n",
    "  group_modify(~ calc.ATE.Odds(.x, log.odds = log.odds)) %>% ungroup() \n",
    "\n",
    "# save plot\n",
    "\n",
    "\n",
    "\n",
    "plot_ATE_ITE_in_group(dev.data = data.dev.grouped.ATE, val.data = data.val.grouped.ATE, \n",
    "                      log.odds = log.odds, ylb = 0, yub = 3.7,\n",
    "                      train.data.name = \"Train\", test.data.name = \"Test\")\n",
    "\n",
    "\n",
    "#True ITE vs TRAM-DAG estimate colored by Treatment\n",
    "\n",
    "\n",
    "ggplot(test.results$data.dev.rs, aes(x=ITE_true, y=ITE, color=Treatment)) +\n",
    "  geom_point() +\n",
    "  geom_abline(slope = 1, intercept = 0, color = \"red\") +\n",
    "  labs(title = \"Training Data\", x = \"True ITE\", y = \"Estimated ITE\") +\n",
    "  theme_minimal() +\n",
    "  theme(legend.position = \"top\")\n",
    "\n",
    "ggplot(test.results$data.val.rs, aes(x=ITE_true, y=ITE, color=Treatment)) +\n",
    "  geom_point() +\n",
    "  geom_abline(slope = 1, intercept = 0, color = \"red\") +\n",
    "  labs(title = \"Test Data\", x = \"True ITE\", y = \"Estimated ITE\") +\n",
    "  theme_minimal() +\n",
    "  theme(legend.position = \"top\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# average treatment effects (TRAM-DAG)\n",
    "mean(test.results$data.dev.rs$ITE)\n",
    "mean(test.results$data.val.rs$ITE)\n",
    "\n",
    "# average treatment effects (glm)\n",
    "mean(test.results.glm$data.dev.rs$ITE)\n",
    "mean(test.results.glm$data.val.rs$ITE)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################################################\n",
    "\n",
    "##### Check predictive power of the model on train set\n",
    "\n",
    "train_df <- dgp_data$test.compl.data$data.dev\n",
    "h_params_orig <- param_model(dgp_data$df_orig_train)\n",
    "Y_prob_tram_dag <- as.numeric(do_probability(h_params_orig))\n",
    "train_df$Y_prob_tram <- Y_prob_tram_dag\n",
    "\n",
    "\n",
    "ggplot(train_df, aes(x = Y_prob, y = Y_prob_tram, color = Treatment)) +\n",
    "  geom_point() +\n",
    "  geom_abline(slope = 1, intercept = 0, color = \"red\") +\n",
    "  labs(x = \"True Probabilities\", y = \"Estimated Probabilities\", title = \"Prob TRAM-DAG (Train)\") +\n",
    "  theme_minimal() +\n",
    "  theme(legend.position = \"top\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# interaction glm\n",
    "glm_interaction <- glm(Y ~ Tr*X1 + X2 + Tr:X1, data = dgp_data$test.compl.data$data.dev, family = binomial(link=\"logit\"))\n",
    "\n",
    "\n",
    "Y_prob_glm_interaction <- predict(glm_interaction, newdata = dgp_data$test.compl.data$data.dev, type = \"response\")\n",
    "\n",
    "train_df$Y_prob_glm <- Y_prob_glm_interaction\n",
    "\n",
    "ggplot(train_df, aes(x = Y_prob, y = Y_prob_glm, color = as.factor(Tr))) +\n",
    "  geom_point() +\n",
    "  geom_abline(slope = 1, intercept = 0, color = \"red\") +\n",
    "  labs(x = \"True Probabilities\", y = \"Estimated Probabilities\", title = \"Prob GLM (Train)\") +\n",
    "  theme_minimal() +\n",
    "  theme(legend.position = \"top\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### Check predictive power of the model on test set\n",
    "\n",
    "test_df <- dgp_data$test.compl.data$data.val\n",
    "\n",
    "# input test data into model\n",
    "h_params_orig <- param_model(dgp_data$df_orig_test)\n",
    "\n",
    "# probabilities for Y=1 on original test data\n",
    "Y_prob_tram_dag <- as.numeric(do_probability(h_params_orig))\n",
    "\n",
    "# true probabilities for y=1 on dgp\n",
    "# Y_prob_dgp <- dgp_data$test.compl.data$data.val$Y_prob\n",
    "\n",
    "test_df$Y_prob_tram <- Y_prob_tram_dag\n",
    "\n",
    "# plot with ggplot the true probabilities Y_prob against the estimated Y_prob_tram_dag and color accoring to Tr\n",
    "\n",
    "ggplot(test_df, aes(x = Y_prob, y = Y_prob_tram, color = Treatment)) +\n",
    "  geom_point() +\n",
    "  geom_abline(slope = 1, intercept = 0, color = \"red\") +\n",
    "  labs(x = \"True Probabilities\", y = \"Estimated Probabilities\", title = \"Prob TRAM-DAG (Test)\") +\n",
    "  theme_minimal() +\n",
    "  theme(legend.position = \"top\")\n",
    "\n",
    "\n",
    "\n",
    "# interaction glm\n",
    "glm_interaction <- glm(Y ~ Tr*X1 + X2 + Tr:X1, data = dgp_data$test.compl.data$data.dev, family = binomial(link=\"logit\"))\n",
    "\n",
    "\n",
    "Y_prob_glm_interaction <- predict(glm_interaction, newdata = dgp_data$test.compl.data$data.val, type = \"response\")\n",
    "\n",
    "test_df$Y_prob_glm <- Y_prob_glm_interaction\n",
    "\n",
    "ggplot(test_df, aes(x = Y_prob, y = Y_prob_glm, color = as.factor(Tr))) +\n",
    "  geom_point() +\n",
    "  geom_abline(slope = 1, intercept = 0, color = \"red\") +\n",
    "  labs(x = \"True Probabilities\", y = \"Estimated Probabilities\", title = \"Prob GLM (Test)\") +\n",
    "  theme_minimal() +\n",
    "  theme(legend.position = \"top\")\n",
    "\n",
    "# \n",
    "# # Y_prob_glm_simple <- predict(glm_simple, newdata = dgp_data$test.compl.data$data.val, type = \"response\")\n",
    "# Y_prob_glm_interaction <- predict(glm_interaction, newdata = dgp_data$test.compl.data$data.val, type = \"response\")\n",
    "# plot(Y_prob_dgp, Y_prob_glm_simple, xlab = \"True Probabilities\", ylab = \"Estimated Probabilities\", main = \"Prob glm_simple\")\n",
    "# abline(0,1, col = \"red\")\n",
    "# plot(Y_prob_dgp, Y_prob_glm_interaction, xlab = \"True Probabilities\", ylab = \"Estimated Probabilities\", main = \"Prob glm_interaction\")\n",
    "# abline(0,1, col = \"red\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## seems like the TRAM-DAG has problems at the edges of the distribution\n",
    "\n",
    "\n",
    "\n",
    "# ### Test\n",
    "# \n",
    "# # input test data into model\n",
    "# h_params_orig <- param_model(dgp_data$df_orig_train)\n",
    "# \n",
    "# # probabilities for Y=1 on original test data\n",
    "# Y_prob_tram_dag <- as.numeric(do_probability(h_params_orig))\n",
    "# \n",
    "# # true probabilities for y=1 on dgp\n",
    "# Y_prob_dgp <- dgp_data$test.compl.data$data.dev$Y_prob\n",
    "# \n",
    "# par(mfrow= c(1,3))\n",
    "# # plot true against estimated\n",
    "# plot(Y_prob_dgp, Y_prob_tram_dag, xlab = \"True Probabilities\", ylab = \"Estimated Probabilities\", main = \"Prob TRAM-DAG\")\n",
    "# abline(0,1, col = \"red\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###### Check the estimated CS(T, X1) #######\n",
    "cs_24_x1_1 <- cs_24_x1_2 <- xs <- seq(-3.2,3.2,length.out=111)\n",
    "\n",
    "idx0 = which(xs == 0) #Index of 0 xs needs to be odd\n",
    "for (i in 1:length(xs)){\n",
    "  #i = 1\n",
    "  x = xs[i]\n",
    "  x1 <- 1   # first x1=1\n",
    "  # Varying x2\n",
    "  X = tf$constant(c(x1, x, 0, 2), shape=c(1L,4L)) \n",
    "  cs_24_x1_1[i] =   param_model(X)[1,4,1]$numpy() #2=CS Term X2->X4 when x1=1\n",
    "  \n",
    "  x1 <- 2   # first x1=2\n",
    "  # Varying x2\n",
    "  X = tf$constant(c(x1, x, 0, 2), shape=c(1L,4L)) \n",
    "  cs_24_x1_2[i] =   param_model(X)[1,4,1]$numpy() #2=CS Term X2->X4 when x1=2\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "q_5 <- quantile(dgp_data$simulated_full_data$X1, c(0.05, 0.95))[1]\n",
    "q_95 <- quantile(dgp_data$simulated_full_data$X1, c(0.05, 0.95))[2]\n",
    "\n",
    "# get real values for the shift from dgp\n",
    "beta_x1 <-  dgp_data$dgp_params$beta_X[1]\n",
    "beta_x1_tx <-  dgp_data$dgp_params$beta_X[1] + dgp_data$dgp_params$beta_TX\n",
    "\n",
    "par(mfrow=c(1,2))\n",
    "\n",
    "delta_0 = cs_24_x1_1[idx0] - 0\n",
    "plot(xs, cs_24_x1_1 - delta_0, main='CS when X1 Control', \n",
    "     sub = 'Effect of x1 & x2 on x4', ylab = 'CS(x2, T=Control)',\n",
    "     xlab='x2', col='red')\n",
    "# abline(0, 2)\n",
    "abline(v=q_5, col = \"blue\", lty = 2)\n",
    "abline(v=q_95, col = \"blue\", lty = 2)\n",
    "lines(xs, -beta_x1*xs, col = \"black\")\n",
    "# if want to compare the treatment effec tin the control plot\n",
    "# lines(xs, -beta_x1_tx*xs, col = \"black\")  \n",
    "legend(\"topleft\", legend=c(\"CS\", \"Quantiles\", \"DGP Effect\"), \n",
    "       col=c(\"red\", \"blue\", \"black\"), lty=c(1, 2, 1), bty=\"n\", cex=0.6)\n",
    "\n",
    "delta_0 = cs_24_x1_2[idx0] - 0\n",
    "plot(xs, cs_24_x1_2 - delta_0, main='CS when X1 Treatment', \n",
    "     sub = 'Effect of x1 & x2 on x4', ylab = 'CS(x2, T=Treatment)',\n",
    "     xlab='x2', col='red')\n",
    "# abline(0, 2)\n",
    "abline(v=q_5, col = \"blue\", lty = 2)\n",
    "abline(v=q_95, col = \"blue\", lty = 2)\n",
    "lines(xs, -beta_x1_tx*xs, col = \"black\")\n",
    "legend(\"topright\", legend=c(\"CS\", \"Quantiles\", \"DGP Effect\"), \n",
    "       col=c(\"red\", \"blue\", \"black\"), lty=c(1, 2, 1), bty=\"n\", cex=0.6)\n",
    "\n",
    "\n",
    "\n",
    "# # when Treatment=Control, the CS should only be the effect of x2 on x4\n",
    "# cs_24_x1_1\n",
    "# \n",
    "# # when x2=0, the CS should only be the intercept, no treatment effect\n",
    "# cs_24_x1_1[idx0]\n",
    "# \n",
    "# # similar for the CS for Treatment=2 when x2=0, this should only be the treatment effect\n",
    "# cs_24_x1_2[idx0]\n",
    "# \n",
    "# # the difference of the two curves at x2=0 should be the main effect of T on x4.\n",
    "# cs_24_x1_2[idx0]- cs_24_x1_1[idx0]\n",
    "# \n",
    "# # DGP main treatment effect is different!\n",
    "# dgp_data$dgp_params$beta_t\n",
    "\n",
    "\n",
    "\n",
    "# same plot but for presentation slide\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "par(mfrow = c(1, 2), mar = c(2, 4, 2, 0.8), mgp = c(1.6, 0.4, 0)) \n",
    "# mgp = c(label pos, tick label pos, line pos)\n",
    "\n",
    "# Plot 1: Control\n",
    "delta_0 = cs_24_x1_1[idx0] - 0\n",
    "plot(xs, cs_24_x1_1 - delta_0, main = 'Control',\n",
    "     ylab = expression(CS(X[1], T == \"Control\")),\n",
    "     xlab = expression(X[1]), col = 'red')\n",
    "lines(xs, -beta_x1 * xs, col = \"black\")\n",
    "legend(\"topleft\", legend = c(\"CS\", \"DGP Effect\"),\n",
    "       col = c(\"red\", \"black\"), lty = c(1, 1), bty = \"n\", cex = 0.6)\n",
    "\n",
    "# Plot 2: Treatment\n",
    "delta_0 = cs_24_x1_2[idx0] - 0\n",
    "plot(xs, cs_24_x1_2 - delta_0, main = 'Treatment',\n",
    "     ylab = expression(CS(X[1], T == \"Treatment\")),\n",
    "     xlab = expression(X[1]), col = 'red')\n",
    "lines(xs, -beta_x1_tx * xs, col = \"black\")\n",
    "legend(\"topright\", legend = c(\"CS\", \"DGP Effect\"),\n",
    "       col = c(\"red\", \"black\"), lty = c(1, 1), bty = \"n\", cex = 0.6)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "par(mfrow = c(1, 2), mar = c(4, 4, 2, 1))  # Reduced margins\n",
    "\n",
    "# Extract observed X1 values\n",
    "x1_obs <- dgp_data$test.compl.data$data.dev$X1\n",
    "\n",
    "# Plot 1: Control\n",
    "delta_0 <- cs_24_x1_1[idx0] - 0\n",
    "plot(xs, cs_24_x1_1 - delta_0, main = 'Control',\n",
    "     ylab = expression(CS(X[1], T == \"Control\")),\n",
    "     xlab = \"\", col = 'red', xaxt = \"n\", cex.lab = 0.9)\n",
    "lines(xs, -beta_x1 * xs, col = \"black\")\n",
    "# axis(side = 1, at = x1_obs, labels = FALSE, tck = -0.015)  # Tick marks only\n",
    "mtext(expression(X[1]), side = 1, line = 2.2, cex = 0.9)   # Closer label\n",
    "legend(\"topleft\", legend = c(\"CS\", \"DGP Effect\"),\n",
    "       col = c(\"red\", \"black\"), lty = c(1, 1), bty = \"n\", cex = 0.6)\n",
    "\n",
    "# Plot 2: Treatment\n",
    "delta_0 <- cs_24_x1_2[idx0] - 0\n",
    "plot(xs, cs_24_x1_2 - delta_0, main = 'Treatment',\n",
    "     ylab = expression(CS(X[1], T == \"Treatment\")),\n",
    "     xlab = \"\", col = 'red', xaxt = \"n\", cex.lab = 0.9)\n",
    "lines(xs, -beta_x1_tx * xs, col = \"black\")\n",
    "# axis(side = 1, at = x1_obs, labels = FALSE, tck = -0.015)\n",
    "mtext(expression(X[1]), side = 1, line = 2.2, cex = 0.9)\n",
    "legend(\"topright\", legend = c(\"CS\", \"DGP Effect\"),\n",
    "       col = c(\"red\", \"black\"), lty = c(1, 1), bty = \"n\", cex = 0.6)\n",
    "\n",
    "\n",
    "\n",
    "#####################################3\n",
    "# Calibration\n",
    "##################################33333\n",
    "\n",
    "\n",
    "# generate a calibration set (newly generated train set with new SEED)\n",
    "calibration_dgp <- dgp(n_obs = 20000, SEED=1)\n",
    "calibration_df <- calibration_dgp$test.compl.data$data.dev\n",
    "\n",
    "\n",
    "# obtain train probabilities:\n",
    "h_params_cal <- param_model(calibration_dgp$df_orig_train)\n",
    "Y_prob_cal <- as.numeric(do_probability(h_params_cal))\n",
    "calibration_df$Y_prob_cal <- Y_prob_cal\n",
    "\n",
    "\n",
    "\n",
    "# \n",
    "# # plot true vs predicted probabilties\n",
    "# ggplot(calibration_df, aes(x = Y_prob, y = Y_prob_cal, color = Treatment)) +\n",
    "#   geom_point() +\n",
    "#   geom_abline(slope = 1, intercept = 0, color = \"red\") +\n",
    "#   labs(x = \"True Probabilities\", y = \"Estimated Probabilities\", title = \"Prob TRAM-DAG (Calibration)\") +\n",
    "#   theme_minimal() +\n",
    "#   theme(legend.position = \"top\")\n",
    "# \n",
    "# # make calibration plot\n",
    "# library(gbm)\n",
    "# par(mfrow=c(1,1))\n",
    "# calibrate.plot(y=calibration_df$Y,\n",
    "#                p=calibration_df$Y_prob_cal,\n",
    "#                distribution = \"bernoulli\")\n",
    "# \n",
    "# # make calibration plot from scratch with 10 bins\n",
    "# library(ggplot2)\n",
    "# library(dplyr)\n",
    "# \n",
    "# # Set number of bins\n",
    "# bins <- 20\n",
    "# \n",
    "# # Create equal-frequency bins based on predicted probabilities\n",
    "# calibration_df <- calibration_df %>%\n",
    "#   mutate(prob_bin = cut(\n",
    "#     Y_prob_cal,\n",
    "#     breaks = quantile(Y_prob_cal, probs = seq(0, 1, length.out = bins + 1), na.rm = TRUE),\n",
    "#     include.lowest = TRUE\n",
    "#   ))\n",
    "# \n",
    "# # Compute average predicted probability and observed proportion in each bin\n",
    "# calibration_summary <- calibration_df %>%\n",
    "#   group_by(prob_bin) %>%\n",
    "#   summarise(\n",
    "#     mean_pred = mean(Y_prob_cal, na.rm = TRUE),\n",
    "#     mean_obs = mean(Y, na.rm = TRUE),\n",
    "#     n = n(),\n",
    "#     .groups = \"drop\"\n",
    "#   )\n",
    "# \n",
    "# # Plot: Calibration curve\n",
    "# library(ggplot2)\n",
    "# library(dplyr)\n",
    "# \n",
    "# # Set number of bins\n",
    "# bins <- 50\n",
    "# \n",
    "# # Create equal-frequency bins based on predicted probabilities\n",
    "# calibration_df <- calibration_df %>%\n",
    "#   mutate(prob_bin = cut(\n",
    "#     Y_prob_cal,\n",
    "#     breaks = quantile(Y_prob_cal, probs = seq(0, 1, length.out = bins + 1), na.rm = TRUE),\n",
    "#     include.lowest = TRUE\n",
    "#   ))\n",
    "# \n",
    "# # Compute average predicted probability and observed proportion in each bin\n",
    "# calibration_summary <- calibration_df %>%\n",
    "#   group_by(prob_bin) %>%\n",
    "#   summarise(\n",
    "#     mean_pred = mean(Y_prob_cal, na.rm = TRUE),\n",
    "#     mean_obs = mean(Y, na.rm = TRUE),\n",
    "#     n = n(),\n",
    "#     .groups = \"drop\"\n",
    "#   )\n",
    "# \n",
    "# # Plot: Calibration curve\n",
    "# ggplot(calibration_summary, aes(x = mean_pred, y = mean_obs)) +\n",
    "#   geom_point(size = 2, color = \"blue\") +\n",
    "#   geom_line(color = \"blue\") +\n",
    "#   geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"red\") +\n",
    "#   labs(\n",
    "#     title = paste(\"Calibration Plot (\", bins, \" bins)\", sep = \"\"),\n",
    "#     x = \"Mean Predicted Probability\",\n",
    "#     y = \"Observed Proportion\"\n",
    "#   ) +\n",
    "#   theme_minimal()\n",
    "# \n",
    "# \n",
    "# \n",
    "# # Plot: pred vs true curve curve\n",
    "# ggplot(calibration_df, aes(x = Y_prob_cal, y = Y_prob)) +\n",
    "#   geom_point(size = 2, color = \"blue\") +\n",
    "#   # geom_line(color = \"blue\") +\n",
    "#   geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"red\") +\n",
    "#   labs(\n",
    "#     title = paste(\"Prediction vs True Plot\", sep = \"\"),\n",
    "#     x = \"Predicted Probability\",\n",
    "#     y = \"True Proportion\"\n",
    "#   ) +\n",
    "#   theme_minimal()\n",
    "# \n",
    "\n",
    "\n",
    "# library(probably)\n",
    "# \n",
    "# calibration_output <- cal_estimate_isotonic(calibration_df,\n",
    "#                       truth = \"Y\",\n",
    "#                       estimate = \"Y_prob_cal\")\n",
    "# calibration_output$estimates\n",
    "\n",
    "\n",
    "# Recalibrate with GAM\n",
    "\n",
    "library(dplyr)\n",
    "library(mgcv)\n",
    "library(binom)\n",
    "library(ggplot2)\n",
    "\n",
    "# Set confidence level and bins\n",
    "my_conf <- 0.95\n",
    "bins <- 10\n",
    "\n",
    "# Create equal-frequency bins\n",
    "calibration_df <- calibration_df %>%\n",
    "  mutate(prob_bin = cut(\n",
    "    Y_prob_cal,\n",
    "    breaks = quantile(Y_prob_cal, probs = seq(0, 1, length.out = bins + 1), na.rm = TRUE),\n",
    "    # breaks = seq(min(Y_prob_cal), max(Y_prob_cal), length.out = bins + 1),\n",
    "    include.lowest = TRUE\n",
    "  ))\n",
    "\n",
    "# Compute bin summaries\n",
    "agg_bin <- calibration_df %>%\n",
    "  group_by(prob_bin) %>%\n",
    "  summarise(\n",
    "    pred_probability = mean(Y_prob_cal),\n",
    "    obs_proportion = mean(Y),\n",
    "    n_pos = sum(Y == 1),\n",
    "    n_total = n(),\n",
    "    .groups = \"drop\"\n",
    "  )\n",
    "\n",
    "# Compute confidence intervals for observed proportions\n",
    "bin_cis <- mapply(\n",
    "  function(x, n) binom.confint(x, n, conf.level = my_conf, methods = \"wilson\")[, c(\"lower\", \"upper\")],\n",
    "  agg_bin$n_pos, agg_bin$n_total, SIMPLIFY = FALSE\n",
    ")\n",
    "cis_df <- do.call(rbind, bin_cis)\n",
    "agg_bin$lo_CI_obs_prop <- cis_df[, 1]\n",
    "agg_bin$up_CI_obs_prop <- cis_df[, 2]\n",
    "agg_bin$width_CI <- abs(agg_bin$up_CI_obs_prop - agg_bin$lo_CI_obs_prop)\n",
    "\n",
    "# Plot predicted against observed including CI\n",
    "ggplot(agg_bin, aes(x = pred_probability, y = obs_proportion)) +\n",
    "  geom_point(color = \"blue\", size = 2) +\n",
    "  geom_errorbar(aes(ymin = lo_CI_obs_prop, ymax = up_CI_obs_prop), width = 0.03) +\n",
    "  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"red\") +\n",
    "  labs(\n",
    "    title = paste(\"Calibration Plot (\", bins, \" bins)\", sep = \"\"),\n",
    "    x = \"Predicted Probability\",\n",
    "    y = \"Observed Proportion\"\n",
    "  ) +\n",
    "  coord_equal() +\n",
    "  theme_minimal()\n",
    "\n",
    "# Fit weighted GAM model\n",
    "raw_w <- 1 / agg_bin$width_CI\n",
    "agg_bin$weights <- raw_w / sum(raw_w)\n",
    "\n",
    "fit_gam <- gam(obs_proportion ~ s(pred_probability), weights = weights, data = agg_bin, gamma = 1)\n",
    "# fit_gam <- gam(obs_proportion ~ s(pred_probability), data = agg_bin, gamma = 1) # without weights\n",
    "plot(fit_gam)\n",
    "\n",
    "# without weights almost same\n",
    "# fit_gam <- gam(obs_proportion ~ s(pred_probability), data = agg_bin, gamma = 0)\n",
    "# plot(fit_gam)\n",
    "\n",
    "# Predict recalibrated probabilities on the calibration set\n",
    "agg_bin$recal_pred <- predict(fit_gam, newdata = data.frame(pred_probability = agg_bin$pred_probability))\n",
    "agg_bin$recal_se <- predict(fit_gam, newdata = data.frame(pred_probability = agg_bin$pred_probability), se.fit = TRUE)$se.fit\n",
    "\n",
    "# Plot\n",
    "ggplot(agg_bin, aes(x = recal_pred, y = obs_proportion)) +\n",
    "  geom_point(color = \"blue\", size = 2) +\n",
    "  geom_errorbar(aes(ymin = lo_CI_obs_prop, ymax = up_CI_obs_prop), width = 0.03) +\n",
    "  geom_errorbarh(aes(xmin = recal_pred - recal_se, xmax = recal_pred + recal_se), height = 0.02) +\n",
    "  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"red\") +\n",
    "  labs(\n",
    "    title = \"GAM-Recalibrated Calibration Plot\",\n",
    "    x = \"Recalibrated Predicted Probability\",\n",
    "    y = \"Observed Proportion\"\n",
    "  ) +\n",
    "  coord_equal() +\n",
    "  theme_minimal()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# check predictions recalibrated on test set\n",
    "\n",
    "\n",
    "# 1. Extract the test set\n",
    "test_df <- dgp_data$test.compl.data$data.val\n",
    "\n",
    "# 2. Compute predicted probabilities on the test set\n",
    "# Assuming you use the same model function as for calibration:\n",
    "h_params_test <- param_model(dgp_data$df_orig_test)  # still trained on training data\n",
    "Y_prob_test <- as.numeric(do_probability(h_params_test))\n",
    "test_df$Y_prob_cal <- Y_prob_test\n",
    "\n",
    "# 3. Recalibrate the test probabilities using the GAM model\n",
    "\n",
    "\n",
    "# Recalibrate using the GAM model from calibration step\n",
    "test_df$Y_prob_recal <- predict(fit_gam, newdata = data.frame(pred_probability = test_df$Y_prob_cal), type = \"response\")\n",
    "# Done! Now test_df has the recalibrated probabilities in Y_prob_recal\n",
    "\n",
    "\n",
    "\n",
    "ggplot(test_df, aes(x = Y_prob_cal, y = Y_prob_recal, color = Treatment)) +\n",
    "  geom_point(alpha = 0.3) +\n",
    "  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"red\") +\n",
    "  labs(title = \"GAM Recalibration on Test Set\",\n",
    "       x = \"Original Predicted Probability\",\n",
    "       y = \"Recalibrated Probability\") +\n",
    "  theme_minimal()\n",
    "\n",
    "#plot the true prob against recalibrated\n",
    "ggplot(test_df, aes(x = Y_prob, y = Y_prob_recal, color = Treatment)) +\n",
    "  geom_point(alpha = 0.3) +\n",
    "  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"red\") +\n",
    "  labs(title = \"True vs Recalibrated Probability on Test Set\",\n",
    "       x = \"True Probability\",\n",
    "       y = \"Recalibrated Probability\") +\n",
    "  theme_minimal()\n",
    "\n",
    "# plot the true prob against un-calibrated (test set)\n",
    "ggplot(test_df, aes(x = Y_prob, y = Y_prob_cal, color = Treatment)) +\n",
    "  geom_point(alpha = 0.3) +\n",
    "  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"red\") +\n",
    "  labs(title = \"True vs Uncalibrated Probability on Test Set\",\n",
    "       x = \"True Probability\",\n",
    "       y = \"Uncalibrated Probability\") +\n",
    "  theme_minimal()\n",
    "\n",
    "\n",
    "# plot the true prob against un-calibrated (train set)\n",
    "ggplot(train_df, aes(x = Y_prob, y = Y_prob_tram)) +\n",
    "  geom_point(alpha = 0.3, color = \"blue\") +\n",
    "  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"red\") +\n",
    "  labs(title = \"True vs Uncalibrated Probability on Test Set\",\n",
    "       x = \"True Probability\",\n",
    "       y = \"Uncalibrated Probability\") +\n",
    "  theme_minimal()\n",
    "\n",
    "# plot the true prob against un-calibrated (calibration set)\n",
    "ggplot(calibration_df, aes(x = Y_prob, y = Y_prob_cal)) +\n",
    "  geom_point(alpha = 0.3, color = \"blue\") +\n",
    "  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"red\") +\n",
    "  labs(title = \"True vs Uncalibrated Probability on Calibration Set\",\n",
    "       x = \"True Probability\",\n",
    "       y = \"Uncalibrated Probability\") +\n",
    "  theme_minimal()\n",
    "\n",
    "\n",
    "\n",
    "################### ITE with recalibrated\n",
    "\n",
    "test_df\n",
    "\n",
    "\n",
    "\n",
    "### Test set\n",
    "\n",
    "# Treatment = 0\n",
    "\n",
    "# set the values of the first column of dgp_data$df_R_test to 0 and add 1 to the last column\n",
    "test_df_T0 <- dgp_data$df_R_test %>%\n",
    "  mutate(\n",
    "    # x1 = 0,  # Set the first column (x1) to 0\n",
    "    x1 = 1, # indicating level 0 control\n",
    "    x4 = x4 + 1 # Add 1 to the last column (x4)\n",
    "  )\n",
    "# convert to tensor\n",
    "test_tf_T0 <- tf$constant(as.matrix(test_df_T0), dtype = 'float32')\n",
    "# outputs for T=0 on the test set\n",
    "h_params_ct <- param_model(test_tf_T0)\n",
    "\n",
    "# Treatment = 1\n",
    "\n",
    "# set the values of the first column of dgp_data$df_R_test to 1 and add 1 to the last column\n",
    "test_df_T1 <- dgp_data$df_R_test %>%\n",
    "  mutate(\n",
    "    # x1 = 1,  # Set the first column (x1) to 1\n",
    "    x1 = 2,  # indicating level 1 treatment\n",
    "    x4 = x4 + 1 # Add 1 to the last column (x4)\n",
    "  )\n",
    "# convert to tensor\n",
    "test_tf_T1 <- tf$constant(as.matrix(test_df_T1), dtype = 'float32')\n",
    "# outputs for T=1 on the test set\n",
    "h_params_tx <- param_model(test_tf_T1)\n",
    "\n",
    "\n",
    "# un-calibrated ITE\n",
    "Y0 <- do_probability(h_params_ct)\n",
    "Y1 <- do_probability(h_params_tx)\n",
    "\n",
    "ITE_i_test <- Y1 - Y0\n",
    "\n",
    "ITE_true <- dgp_data$test.compl.data$data.val$ITE_true\n",
    "par(mfrow=c(1,2))\n",
    "plot(ITE_true, ITE_i_test, xlab = \"True ITE\", ylab = \"Estimated ITE TRAM-DAG\", main = \"ITE (un-calibrated)\")\n",
    "abline(0,1, col=\"red\")\n",
    "\n",
    "df_test_uncalibrated <- data.frame(\n",
    "  ITE_true = ITE_true,\n",
    "  ITE_i_test = as.numeric(ITE_i_test),\n",
    "  Treatment = dgp_data$test.compl.data$data.val$Treatment\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Recalibrated ITE\n",
    "Y0_recal <- predict(fit_gam, newdata = data.frame(pred_probability = as.numeric(Y0)), type = \"response\")\n",
    "Y1_recal <- predict(fit_gam, newdata = data.frame(pred_probability = as.numeric(Y1)), type = \"response\")\n",
    "\n",
    "\n",
    "ITE_i_test_recal <- Y1_recal - Y0_recal\n",
    "\n",
    "ITE_true <- dgp_data$test.compl.data$data.val$ITE_true\n",
    "\n",
    "plot(ITE_true, ITE_i_test_recal, xlab = \"True ITE\", ylab = \"Recalibrated ITE TRAM-DAG\", main = \"ITE (re-calibrated)\")\n",
    "abline(0,1, col=\"red\")\n",
    "\n",
    "\n",
    "df_test_recalibrated <- data.frame(\n",
    "  ITE_true = ITE_true,\n",
    "  ITE_i_test_recal = as.numeric(ITE_i_test_recal),\n",
    "  Treatment = dgp_data$test.compl.data$data.val$Treatment\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# ggplot of df_test_uncalibrated\n",
    "ggplot(df_test_uncalibrated, aes(x = ITE_true, y = ITE_i_test, color = Treatment)) +\n",
    "  geom_point() +\n",
    "  geom_abline(slope = 1, intercept = 0, color = \"red\") +\n",
    "  labs(title = \"Uncalibrated ITE TRAM-DAG\", x = \"True ITE\", y = \"Estimated ITE\") +\n",
    "  theme_minimal() +\n",
    "  theme(legend.position = \"top\")\n",
    "\n",
    "# ggplot of df_test_recalibrated\n",
    "ggplot(df_test_recalibrated, aes(x = ITE_true, y = ITE_i_test_recal, color = Treatment)) +\n",
    "  geom_point() +\n",
    "  geom_abline(slope = 1, intercept = 0, color = \"red\") +\n",
    "  labs(title = \"Recalibrated ITE TRAM-DAG\", x = \"True ITE\", y = \"Estimated ITE\") +\n",
    "  theme_minimal() +\n",
    "  theme(legend.position = \"top\")\n",
    "\n",
    "# save recalibrated plot\n",
    "# png(\"C:/Users/kraeh/OneDrive/Dokumente/Desktop/UZH_Biostatistik/Masterarbeit/MA_Mike/presentation_report/intermediate_presentation/img/ITE_recal.png\",\n",
    "#     width = 800, height = 600, res = 150)\n",
    "# ggplot(df_test_recalibrated, aes(x = ITE_true, y = ITE_i_test_recal, color = Treatment)) +\n",
    "#   geom_point() +\n",
    "#   geom_abline(slope = 1, intercept = 0, color = \"red\") +\n",
    "#   labs(title = \"Recalibrated ITE (Test)\", x = \"True ITE\", y = \"Estimated ITE\") +\n",
    "#   theme_minimal() +\n",
    "#   theme(legend.position = \"top\")\n",
    "# dev.off()\n",
    "\n",
    "\n",
    "\n",
    "# get recalibrated test set values\n",
    "ITE_i_train_recal <- predict(fit_gam, newdata = data.frame(pred_probability = data.dev.rs$ITE), type = \"response\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# make ate plot\n",
    "\n",
    "breaks <- c(-0.75, -0.4, -0.2, 0.1, 0.5)\n",
    "log.odds <- F\n",
    "data.dev.grouped.ATE.recal <- data.dev.rs %>% \n",
    "  # add as.numeric(ITE_i_test_recal) to variable ITE\n",
    "  mutate(ITE = as.numeric(ITE_i_train_recal)) %>%\n",
    "  mutate(ITE.Group = cut(ITE, breaks = breaks, include.lowest = T)) %>%\n",
    "  dplyr::filter(!is.na(ITE.Group)) %>%\n",
    "  group_by(ITE.Group) %>% \n",
    "  group_modify(~ calc.ATE.Odds(.x, log.odds = log.odds)) %>% ungroup()\n",
    "data.val.grouped.ATE.recal <- data.val.rs %>% \n",
    "  # add as.numeric(ITE_i_test_recal) to variable ITE\n",
    "  mutate(ITE = as.numeric(ITE_i_test_recal)) %>%\n",
    "  mutate(ITE.Group = cut(ITE, breaks = breaks, include.lowest = T)) %>%\n",
    "  dplyr::filter(!is.na(ITE.Group)) %>%\n",
    "  group_by(ITE.Group) %>%\n",
    "  group_modify(~ calc.ATE.Odds(.x, log.odds = log.odds)) %>% ungroup() \n",
    "\n",
    "png(\"C:/Users/kraeh/OneDrive/Dokumente/Desktop/UZH_Biostatistik/Masterarbeit/MA_Mike/presentation_report/intermediate_presentation/img/ATE_ITE_recal.png\",\n",
    "    width = 800, height = 600, res = 150)\n",
    "plot_ATE_ITE_in_group(dev.data = data.dev.grouped.ATE.recal, val.data = data.val.grouped.ATE.recal, \n",
    "                      log.odds = log.odds, ylb = 0, yub = 3.7,\n",
    "                      train.data.name = \"Train\", test.data.name = \"Test\")\n",
    "dev.off()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################################\n",
    "# Follwoing plots used for identification of problems In complex shift \n",
    "#########################################\n",
    "\n",
    "# no more problems in last model with Relu and batchnormalization: \n",
    "\n",
    "# x1_ordinal_12__ModelCS_E450CS\n",
    "\n",
    "\n",
    "### search for reason of bad border estimation\n",
    "\n",
    "# problems appear outside of TRUE ITE of c(-0.45, 0.20)\n",
    "\n",
    "# make a new variable in test.results$data.dev.rs for ITE below interval, between and above  c(-0.45, 0.20)\n",
    "\n",
    "dat <- test.results$data.dev.rs %>%\n",
    "  mutate(\n",
    "    ITE_group = case_when(\n",
    "      ITE_true < -0.45 ~ \"below\",\n",
    "      ITE_true >= -0.45 & ITE_true <= 0.20 ~ \"between\",\n",
    "      ITE_true > 0.20 ~ \"above\"\n",
    "    )\n",
    "  )\n",
    "\n",
    "dat$Y_prob_tram <- Y_prob_tram_dag\n",
    "\n",
    "\n",
    "# plot the true probabilities Y_prob against the estimated Y_prob_tram_dag and color according to ITE_group\n",
    "ggplot(dat, aes(x = Y_prob, y = Y_prob_tram, color = ITE_group)) +\n",
    "  # geom_point() +\n",
    "  # make the points see through (like alpha?)\n",
    "  geom_point(alpha = 0.3) +\n",
    "  # select other color palette\n",
    "  scale_color_manual(values = c(\"below\" = \"red\", \"between\" = \"green\", \"above\" = \"blue\")) +\n",
    "  geom_abline(slope = 1, intercept = 0, color = \"red\") +\n",
    "  labs(x = \"True Probabilities\", y = \"Estimated Probabilities\", title = \"Prob TRAM-DAG (Train Middle)\") +\n",
    "  theme_minimal() +\n",
    "  theme(legend.position = \"top\")\n",
    "\n",
    "# plot X1 against Y_prob_tram and color according to ITE_group\n",
    "ggplot(dat, aes(x = X1, y = Y_prob_tram, color = ITE_group)) +\n",
    "  geom_point() +\n",
    "  # select other color palette\n",
    "  scale_color_manual(values = c(\"below\" = \"red\", \"between\" = \"green\", \"above\" = \"blue\")) +\n",
    "  labs(x = \"X1\", y = \"Estimated Probabilities\", title = \"Prob TRAM-DAG (Train Middle)\") +\n",
    "  theme_minimal() +\n",
    "  theme(legend.position = \"top\")\n",
    "\n",
    "# plot X1 against Tr and color according to ITE_group\n",
    "ggplot(dat, aes(x = X1, y = Tr, color = ITE_group)) +\n",
    "  geom_point() +\n",
    "  # select other color palette\n",
    "  scale_color_manual(values = c(\"below\" = \"red\", \"between\" = \"green\", \"above\" = \"blue\")) +\n",
    "  labs(x = \"X1\", y = \"Treatment\", title = \"Prob TRAM-DAG (Train Middle)\") +\n",
    "  theme_minimal() +\n",
    "  theme(legend.position = \"top\")\n",
    "\n",
    "# plot X1 against Y and color according to ITE_group\n",
    "ggplot(dat, aes(x = X1, y = Y, color = ITE_group)) +\n",
    "  geom_point() +\n",
    "  # select other color palette\n",
    "  scale_color_manual(values = c(\"below\" = \"red\", \"between\" = \"green\", \"above\" = \"blue\")) +\n",
    "  labs(x = \"X1\", y = \"Y\", title = \"Prob TRAM-DAG (Train Middle)\") +\n",
    "  theme_minimal() +\n",
    "  theme(legend.position = \"top\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# plot X1 against Y_prob_tram and color according to ITE_group, but do this separately grouped by Treatment\n",
    "ggplot(dat, aes(x = X1, y = Y_prob_tram, color = ITE_group)) +\n",
    "  geom_point() +\n",
    "  # select other color palette\n",
    "  scale_color_manual(values = c(\"below\" = \"red\", \"between\" = \"green\", \"above\" = \"blue\")) +\n",
    "  facet_wrap(~Tr) +\n",
    "  labs(x = \"X1\", y = \"Estimated Probabilities\", title = \"Prob TRAM-DAG (Train Middle)\") +\n",
    "  theme_minimal() +\n",
    "  theme(legend.position = \"top\")\n",
    "\n",
    "\n",
    "\n",
    "# plot X1 against Y and color according to ITE_group, but do this separately grouped by Treatment\n",
    "ggplot(dat, aes(x = X1, y = Y, color = ITE_group)) +\n",
    "  geom_point() +\n",
    "  # select other color palette\n",
    "  scale_color_manual(values = c(\"below\" = \"red\", \"between\" = \"green\", \"above\" = \"blue\")) +\n",
    "  facet_wrap(~Tr) +\n",
    "  labs(x = \"X1\", y = \"Y\", title = \"Prob TRAM-DAG (Train Middle)\") +\n",
    "  theme_minimal() +\n",
    "  theme(legend.position = \"top\")\n",
    "\n",
    "\n",
    "# plot X2 against Y and color according to ITE_group, but do this separately grouped by Treatment\n",
    "ggplot(dat, aes(x = X2, y = Y, color = ITE_group)) +\n",
    "  geom_point() +\n",
    "  # select other color palette\n",
    "  scale_color_manual(values = c(\"below\" = \"red\", \"between\" = \"green\", \"above\" = \"blue\")) +\n",
    "  facet_wrap(~Tr) +\n",
    "  labs(x = \"X2\", y = \"Y\", title = \"Prob TRAM-DAG (Train Middle)\") +\n",
    "  theme_minimal() +\n",
    "  theme(legend.position = \"top\")\n",
    "\n",
    "\n",
    "# make a summary of the proportion of Y=1 in each group\n",
    "dat_summary <- dat %>%\n",
    "  group_by(ITE_group) %>%\n",
    "  summarise(\n",
    "    mean_Y_prob = mean(Y_prob),\n",
    "    mean_Y_prob_tram = mean(Y_prob_tram),\n",
    "    mean_ITE_true = mean(ITE_true),\n",
    "    mean_ITE = mean(ITE),\n",
    "    mean_Y = mean(Y),\n",
    "    mean_Tr = mean(Tr)\n",
    "  )\n",
    "dat_summary\n",
    "\n",
    "\n",
    "# select only \"below\" group\n",
    "dat_below_0.5 <- dat %>%\n",
    "  filter(ITE_group == \"below\", \n",
    "         Y_prob < 0.5)\n",
    "\n",
    "# summarize dat_below\n",
    "dat_below_summary <- dat_below_0.5 %>%\n",
    "  summarise(\n",
    "    mean_Y_prob = mean(Y_prob),\n",
    "    mean_Y_prob_tram = mean(Y_prob_tram),\n",
    "    mean_ITE_true = mean(ITE_true),\n",
    "    mean_ITE = mean(ITE),\n",
    "    mean_Y = mean(Y),\n",
    "    mean_Tr = mean(Tr)\n",
    "  )\n",
    "\n",
    "# summarize dat_below_0.5\n",
    "dat_below_0.5_summary <- dat_below_0.5 %>%\n",
    "  summarise(\n",
    "    mean_Y_prob = mean(Y_prob),\n",
    "    mean_Y_prob_tram = mean(Y_prob_tram),\n",
    "    mean_ITE_true = mean(ITE_true),\n",
    "    mean_ITE = mean(ITE),\n",
    "    mean_Y = mean(Y),\n",
    "    mean_Tr = mean(Tr)\n",
    "  )\n",
    "\n",
    "\n",
    "# plot dat_below_0.5_summary true prob vs estimate\n",
    "ggplot(dat_below_0.5, aes(x = Y_prob, y = Y_prob_tram)) +\n",
    "  geom_point() +\n",
    "  geom_abline(slope = 1, intercept = 0, color = \"red\") +\n",
    "  labs(x = \"True Probabilities\", y = \"Estimated Probabilities\", title = \"Prob TRAM-DAG (Train Middle)\") +\n",
    "  theme_minimal() +\n",
    "  theme(legend.position = \"top\")\n",
    "\n",
    "# plot dat_below_0.5_summary true prob vs estimate, color by Y\n",
    "ggplot(dat_below_0.5, aes(x = Y_prob, y = Y_prob_tram, color = X1)) +\n",
    "  geom_point() +\n",
    "  geom_abline(slope = 1, intercept = 0, color = \"red\") +\n",
    "  labs(x = \"True Probabilities\", y = \"Estimated Probabilities\", title = \"Prob TRAM-DAG (Train Middle)\") +\n",
    "  theme_minimal() +\n",
    "  theme(legend.position = \"top\")\n",
    "\n",
    "dat_below_0.5_X1_2 <- dat_below_0.5 %>%\n",
    "  filter(X1 < -2)\n",
    "\n",
    "# summarize dat_below_0.5_X1_2\n",
    "dat_below_0.5_X1_2_summary <- dat_below_0.5_X1_2 %>%\n",
    "  summarise(\n",
    "    mean_Y_prob = mean(Y_prob),\n",
    "    mean_Y_prob_tram = mean(Y_prob_tram),\n",
    "    mean_ITE_true = mean(ITE_true),\n",
    "    mean_ITE = mean(ITE),\n",
    "    mean_Y = mean(Y),\n",
    "    mean_Tr = mean(Tr)\n",
    "  )\n",
    "dat_below_0.5_X1_2_summary\n",
    "\n",
    "#plot X1 against X2\n",
    "ggplot(dat_below_0.5_X1_2, aes(x = X1, y = X2)) +\n",
    "  geom_point() +\n",
    "  # select other color palette\n",
    "  labs(x = \"X1\", y = \"X2\", title = \"Prob TRAM-DAG (Train Middle)\") +\n",
    "  theme_minimal() +\n",
    "  theme(legend.position = \"top\")\n",
    "\n",
    "# plot True against estimated probabilities\n",
    "ggplot(dat_below_0.5_X1_2, aes(x = Y_prob, y = Y_prob_tram)) +\n",
    "  geom_point() +\n",
    "  geom_abline(slope = 1, intercept = 0, color = \"red\") +\n",
    "  labs(x = \"True Probabilities\", y = \"Estimated Probabilities\", title = \"Prob TRAM-DAG (Train Middle)\") +\n",
    "  theme_minimal() +\n",
    "  theme(legend.position = \"top\")\n",
    "\n",
    "\n",
    "\n",
    "# analyze for X1 c(-2, 1.5)\n",
    "\n",
    "dat <- test.results$data.dev.rs %>%\n",
    "  mutate(\n",
    "    X1_group = case_when(\n",
    "      X1 < -2 ~ \"below\",\n",
    "      X1 >= -2 & X1 <= 1.5 ~ \"between\",\n",
    "      X1 > 1.5 ~ \"above\"\n",
    "    )\n",
    "  )\n",
    "\n",
    "dat$Y_prob_tram <- Y_prob_tram_dag\n",
    "\n",
    "\n",
    "# plot the true probabilities Y_prob against the estimated Y_prob_tram_dag and color according to X1_group\n",
    "ggplot(dat, aes(x = Y_prob, y = Y_prob_tram, color = X1_group)) +\n",
    "  # geom_point() +\n",
    "  # make the points see through (like alpha?)\n",
    "  geom_point(alpha = 0.3) +\n",
    "  # select other color palette\n",
    "  scale_color_manual(values = c(\"below\" = \"red\", \"between\" = \"green\", \"above\" = \"blue\")) +\n",
    "  geom_abline(slope = 1, intercept = 0, color = \"red\") +\n",
    "  labs(x = \"True Probabilities\", y = \"Estimated Probabilities\", title = \"Prob TRAM-DAG (Train Middle)\") +\n",
    "  theme_minimal() +\n",
    "  theme(legend.position = \"top\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# check distribution of Y against X1 on treat and control (maybe reason for weird shift for treatment group)\n",
    "\n",
    "\n",
    "#train set\n",
    "\n",
    "treat <- dgp_data$test.compl.data$data.dev %>%\n",
    "  filter(Tr == 1) \n",
    "contr <- dgp_data$test.compl.data$data.dev %>%\n",
    "  filter(Tr == 0)\n",
    "\n",
    "\n",
    "# fit gam for binary response Y with continuous predictor X1 on treat, \n",
    "\n",
    "gam_model_treat <- gam(Y ~ s(X1)+ s(X2), data = treat, family = binomial(link=\"logit\"), gamma=0.4)\n",
    "# select only plot for X1\n",
    "plot(gam_model_treat, main= \"Y~s(X1) treated (train set)\", \n",
    "     xlab = \"X1\", cex.axis=0.8, cex.lab=0.8, cex.main=0.8, select=1)\n",
    "\n",
    "\n",
    "# fit gam for binary response Y with continuous predictor X1 on contr,\n",
    "gam_model_contr <- gam(Y ~ s(X1) + s(X2), data = contr, family = binomial(link=\"logit\"), gamma=0.4)\n",
    "plot(gam_model_contr, main= \"Y~s(X1) control (train set)\", \n",
    "     xlab = \"X1\", cex.axis=0.8, cex.lab=0.8, cex.main=0.8, select=1)\n",
    "\n",
    "\n",
    "# same on test set\n",
    "\n",
    "treat_test <- dgp_data$test.compl.data$data.val %>%\n",
    "  filter(Tr == 1)\n",
    "contr_test <- dgp_data$test.compl.data$data.val %>%\n",
    "  filter(Tr == 0)\n",
    "\n",
    "# fit gam for binary response Y with continuous predictor X1 on treat,\n",
    "gam_model_treat_test <- gam(Y ~ s(X1) + s(X2), data = treat_test, family = binomial(link=\"logit\"), gamma=0.4)\n",
    "plot(gam_model_treat_test, main= \"Y~s(X1) treated (test set)\", \n",
    "     xlab = \"X1\", cex.axis=0.8, cex.lab=0.8, cex.main=0.8, select=1)\n",
    "\n",
    "# fit gam for binary response Y with continuous predictor X1 on contr,\n",
    "gam_model_contr_test <- gam(Y ~ s(X1)+ s(X2), data = contr_test, family = binomial(link=\"logit\"), gamma=0.4)\n",
    "plot(gam_model_contr_test)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
